///////////////////////////////////////////////////
//
//  Based on sha256-armv4.pl form OpenSSL 1.0.2j
//
///////////////////////////////////////////////////


#verbatim
module sha256_refined {
import opened sha256_ARMdecls = ARMdecls
import opened sha256_ARMspartan = ARMspartan
import opened sha256_sha256_i = sha256_i
import opened sha256_sha256_refined_helpers_i = sha256_refined_helpers_i
import opened sha256_sha256_refined_invariants_i = sha256_refined_invariants_i 

function method Sigma0(i:int) : word
    requires 0 <= i < 3;
{
    [2, 13, 22][i]
}

function method Sigma1(i:int) : word
    requires 0 <= i < 3;
{
    [6, 11, 25][i]
}

function method sigma0(i:int) : word
    requires 0 <= i < 3;
{
    [7, 18, 3][i]
}

function method sigma1(i:int) : word
    requires 0 <= i < 3;
{
    [17, 19, 10][i]
}

type SHA_step = i | 0 <= i < 64

function method GetReg(r:int) : ARMReg
    requires 0 <= r <= 12;
{
         if r ==  0 then R0
    else if r ==  1 then R1
    else if r ==  2 then R2
    else if r ==  3 then R3
    else if r ==  4 then R4
    else if r ==  5 then R5
    else if r ==  6 then R6
    else if r ==  7 then R7
    else if r ==  8 then R8
    else if r ==  9 then R9
    else if r == 10 then R10
    else if r == 11 then R11
    else R12 
}

#endverbatim

procedure {:refined} {:timeLimitMultiplier 2} Body_00_15(
    inline i:SHA_step,
    inline perm:perm_index,
    inline input_slot:word,
    inline i_plus_2:word,
    inline i_plus_15:word,
    ghost input_ptr:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand t4:word,
    //inout operand inp:word,
    inout operand a:word,
          operand b:word,
          operand c:word,
    inout operand d:word,
          operand e:word,
          operand f:word,
          operand g:word,
    inout operand h:word
    ) returns (
    ghost trace_out:SHA256Trace
    )
requires/ensures
    ValidAddr(mem, sp + input_slot);
reads 
    sp; globals;
modifies 
    mem; lr;
requires {:refined false}
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(GetReg(if Even(i) then 12 else 3));
    @t3 == OReg(GetReg(if Even(i) then  3 else 12));
    @t4 == OReg(R1);
    //@inp == OReg(R1);
    @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
    @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
    @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
    @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
    @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
    @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
    @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
    @h  == OReg(GetReg(4+ApplyPerm(7, perm)));
requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp, 19);

    // Ghost input matches in-memory input  
    SeqLength(input) == 16;
    i < 16 ==>
        (input_ptr + 16*4 < 0x1_0000_0000)
     && (input_ptr + 16*4 < sp || sp + 19*4 <= input_ptr)    // input_ptr doesn't alias the stack
     && ValidAddrs(mem, input_ptr, 16)
     && InputMatchesMemory(input, input_ptr, 16, mem);
requires
    // K table adjusted properly
    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
    AddressOfGlobal(K_SHA256s()) + 4*64 < 0x1_0000_0000;    // We won't wrap around while accessing K_SHA256s
    lr == AddressOfGlobal(K_SHA256s()) + 4*i;
    SeqLength(globals[K_SHA256s()]) == 256;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    i < 16 ==> t4 == input_ptr + (i+1)*4;    

    input_slot == CheapMod16(i)*4;

    i >= 15 ==> i_plus_2  == CheapMod16(i+ 2)*4 && ValidAddr(mem, sp+i_plus_2);
    i >= 15 ==> i_plus_15 == CheapMod16(i+15)*4 && ValidAddr(mem, sp+i_plus_15);

    // SHA semantics
    SeqLength(trace_in.H) > 0;
    IsSHA256TraceReadyForStep(trace_in, i);
    if i == 0 || i >= 16 then last(last(trace_in.atoh)) == atoh_c(a, b, c, d, e, f, g, h)
    else last(last(trace_in.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h);

    // t1 holds the current value of W
    t1 == (if (i < 16) then input[i] else last(trace_in.W)[i]);

    // The first 16 values in W are the byte-swapped version of the input words
    forall j :: 0 <= j < 16 ==> last(trace_in.W)[j] == bswap32(input[j]);

    // All previous Ws are in memory where we expect them
    WsMatchMemory(trace_in, i, sp, mem);

    // SHA tactics
    t3 == BitwiseXor(b, c);
    i >= 16 ==> RotateRight(t0, Sigma1(0)) == BSIG1(e);

ensures
    t2 == BitwiseXor(a, b);
    a == (if 0 < i < 16 then old(BitwiseAdd32(a, t2)) else old(a));
    i >= 15 ==> t4 == mem[sp+i_plus_15];
    lr == old(lr) + 4;

    // Updated input ptr
    if i < 15 then t4 == input_ptr + (i+2)*4              // Advanced input ptr
    else 
        t4 == mem[sp + i_plus_15]
     && (if i == 15 then mem[sp+17*4] == input_ptr+16*4   // We stored the advanced input ptr on the stack
         else mem[sp+17*4] == old(mem[sp+17*4]));               // We preserved the input ptr on the stack

    // Memory framing: We only touch the stack
    forall addr:word :: old(mem)?[addr] && (addr < sp || addr >= sp + 19*4) ==> mem?[addr] && mem[addr] == old(mem)[addr];
    mem[sp + 16*4] == old(mem)[sp + 16*4];
    mem[sp + 18*4] == old(mem)[sp + 18*4];

    IsSHA256TraceReadyForStep(trace_out, i+1);
    trace_out.M == trace_in.M;
    trace_out.H == trace_in.H;
    trace_out.W == trace_in.W;
    // t1 holds the next value of W
    t1 == (if i + 1 < 16 then input[i + 1] else if i + 1 <= 64 then mem[sp + i_plus_2] else t1); //last(trace_out.W)[i + 1] else t1)
    WsMatchMemory(trace_out, i+1, sp, mem);
    // The atohs almost match the outgoing variables
    last(last(trace_out.atoh)) == atoh_c(BitwiseAdd32(h, t3), a, b, c, d, e, f, g);
{
    inline if (i < 16) {
        inline if (i == 15) {
            // Save a copy of the incremented input pointer, so we can free up t4
            assert 68 == 17*4;
            rSTR(t4, sp, 68);     
        }

        rEORShift(t0, e, e, RORShift(Sigma1(1) - Sigma1(0)));
        // Optimize the first case.  This is an optimization that OpenSSL misses! 
        inline if (i != 0) {
            rADDWrap(a, a, t2);  // h += Maj(a,b,c) from the past?
        }
        rEORShift(t0, t0, e, RORShift(Sigma1(2) - Sigma1(0)));   // Sigma1(e)
        rREV(t1, t1);
    }

    rLDRglobal(t2, K_SHA256s().sym, lr, 0);
    rADDWrap(lr, lr, 4);    // TODO: OpenSSL does this in one instruction with a load-and-increment.  
    lemma_mod_in_bounds2(i, AddressOfGlobal(K_SHA256s()), old(lr), lr);
    rADDWrap(h, h, t1);      //  h+=X[i]  BP: X[i] = input[i]?
    rSTR(t1, sp, input_slot);  // @ BP: Save a copy of W[i] for use in subsequent W calculations
    rEOR(t1, f, g);
    ghost var old_h := h;
    rADDWrapShift(h, h, t0, RORShift(Sigma1(0))); // h += Sigma1(e)

    // Prove that we computed Sigma1(e) correctly:
    forall :: h == BitwiseAdd32(old_h, BSIG1(e))
    {
        reveal BSIG1;
        lemma_BSIGOptimization(e, 6, 11, 25);
    }

    rAND(t1, t1, e);
    rADDWrap(h, h, t2);  // h += K256(i)
    rEOR(t1, t1, g);     // Ch(e,f,g)
    
    assert t1 == Ch(e, f, g) by { lemma_Ch(e, f, g, t1); }

    rEORShift(t0, a, a, RORShift(Sigma0(1) - Sigma0(0)));
    rADDWrap(h, h, t1);  // h += Ch(e,f,g)

    ghost var old_t1 := if i < 16 then bswap32(old(t1)) else old(t1);
    assert h == BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(old(h), old_t1), BSIG1(e)), K_SHA256(i)), Ch(e, f, g));
    lemma_BitwiseAdd32Associates5(old(h), old_t1, BSIG1(e), K_SHA256(i), Ch(e, f, g), h);

//    #if $i==31
//        and  $t2,$t2,#0xff
//        cmp  $t2,#0xf2      @ done?
//    #endif

    inline if (i < 15) {    
         assert ValidAddr(old(mem), t4); // OBSERVE
         rLDR(t1, t4, 0);    // Prefetch
         rADDWrap(t4, t4, 4);   // Advance to the next input  // TODO: OpenSSL does this in one instruction with a load-and-increment
         lemma_mod_in_bounds(i, input_ptr, old(t4), t4);
//         assert old(t4) + 4 == input_ptr + (i+1)*4 + 4 == input_ptr + (i+2)*4;
//         assert input_ptr + (i+2)*4 < 0x1_0000_0000;
         assert t4 == old(t4) + 4;
         rEOR(t2, a, b);            //  a^b, b^c in next round
    } else {
         assert ValidAddr(old(mem), sp+i_plus_2);  // OBSERVE
         assert ValidAddr(old(mem), sp+i_plus_15); // OBSERVE
         rLDR(t1, sp, i_plus_2);     // @ from future BODY_16_xx 
         rEOR(t2, a, b);             //  a^b, b^c in next round
         rLDR(t4, sp, i_plus_15);    // @ from future BODY_16_xx
    }
    rEORShift(t0,t0,a, RORShift(Sigma0(2)-Sigma0(0))); // Sigma0(a)
    rAND(t3,t3,t2);      // (b^c)&=(a^b)
    rADDWrap(d,d,h);     // d+=h
    rEOR(t3,t3,b);       // Maj(a,b,c)
    assert t3 == Maj(a,b,c) by { lemma_Maj(a, b, c, t3); }
    old_h := h;
    rADDWrapShift(h,h,t0, RORShift(Sigma0(0)));   // h+=Sigma0(a)

    // Prove we computed Sigma0(a) correctly:
    forall :: h == (old_h + BSIG0(a)) % 0x1_0000_0000
    {
        reveal BSIG0;
        lemma_BSIGOptimization(a, 2, 13, 22);
    }

    ghost var T1 := BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(old(h), BSIG1(e)),
                                                           Ch(e,f,g)),
                                              K_SHA256(i)),
                                 old_t1);
    assert BitwiseAdd32(h, t3) == BitwiseAdd32(T1, BitwiseAdd32(BSIG0(a), t3)) by
           { lemma_BitwiseAdd32Associates3'(T1, BSIG0(a), t3); }

    // Construct a trace_out
    ghost var old_a := if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2));
    ghost var old_atoh := old(atoh_c(old_a, b, c, d, e, f, g, h));
    ghost var new_atoh := atoh_c(BitwiseAdd32(h, t3), old_a, old(b), old(c), d, old(e), old(f), old(g));
    lemma_BitwiseAdd32_properties(old(a));
    assert i == 0 ==> BitwiseAdd32(old(a), 0) == old(a);   // OBSERVE
    assert old_atoh.a == a;     // OBSERVE
     

    ghost var new_atoh_list := last(trace_in.atoh) + seq(new_atoh);
    trace_out := trace_in.(atoh := SeqDrop(trace_in.atoh, SeqLength(trace_in.H)-1) + seq(trace_in.atoh[SeqLength(trace_in.H)-1] + seq(new_atoh)));

    // OBSERVE: Triggers gallore!
    assert TBlk(SeqLength(trace_in.H)-1) && TBlk(SeqLength(trace_in.H)) && TStep(i) && TStep(i + 1);
    ghost var superfluous_state_in  := SHA256_state_c(last(trace_in.H), last(trace_in.W), old_atoh);
    ghost var superfluous_state_out := SHA256_state_c(last(trace_out.H), last(trace_out.W), new_atoh);
    lemma_SHA256TransitionOKAfterSettingAtoH(trace_in, superfluous_state_in, trace_out, superfluous_state_out, i);

    assert IsSHA256TraceReadyForStep(trace_out, i+1);

    // Prove that stack is still valid
    lemma_ValidAddrsPreservation(old(mem), mem, sp, 19, sp + 68, sp + input_slot);

    // Help prove that the input is still intact
    ghost if (i < 16) {
        lemma_InputPreservation(old(mem), mem, input, input_ptr, 16, sp + 68, sp + input_slot);

        // Prove input is still valid src
        //lemma_ValidSrcAddrsPreservation(old(mem), mem, input_ptr, 16, input_taint, sp + 68, sp + input_slot);
     }
   
    // Prove we updated the Ws correctly
    lemma_WsIncrement(old(mem), mem, trace_in, trace_out, sp, i, sp + 68, sp + input_slot);
    assert { :split_here} true;
    assert ValidAddr(old(mem), sp + 16*4); // OBSERVE
    assert ValidAddr(old(mem), sp + 18*4); // OBSERVE
    assert mem[sp + 18*4] == old(mem)[sp + 18*4];
}

#verbatim

predicate Body_00_15LoopStateInvariantBreakdown(
    orig_mem:memmap,
    mem:memmap,
    input_ptr:word,
    orig_trace:SHA256Trace,
    current_trace:SHA256Trace,
    i:int,
    sp:word,
    globals:map<operand,seq<word>>,
    lr:word,
    t1:word,
    t2:word,
    t3:word,
    t4:word,
    input:seq<word>,
    a:word, b:word, c:word, d:word, e:word, f:word, g:word, h:word
    )
{
    0 <= i <= 16
 // Stack is accessible in both old and new mem
 && ValidAddrs(orig_mem, sp, 19)
 && ValidAddrs(mem, sp, 19)
 && ValidAddr(mem, sp + CheapMod16(i)*4)
 && ValidAddr(mem, sp + CheapMod16(i+9)*4)

    // K table adjusted properly
 && ValidGlobalsAddr(globals, K_SHA256s().sym, lr)
 && K_SHA256s() in globals
 && AddressOfGlobal(K_SHA256s()) + 4*64 < 0x1_0000_0000    // We won't wrap around while accessing K_SHA256s
 && lr == AddressOfGlobal(K_SHA256s()) + 4*i
 && |globals[K_SHA256s()]| == 256
 && (forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j))

    // Ghost input matches in-memory input
 && SeqLength(input) == 16
 && (i < 16 ==>
        (input_ptr + 16*4 < 0x1_0000_0000)
     && (input_ptr + 16*4 < sp || sp + 19*4 <= input_ptr)    // input_ptr doesn't alias the stack
     && ValidAddrs(mem, input_ptr, 16)
     && InputMatchesMemory(input, input_ptr, 16, mem)
    )

 && ValidAddr(mem, sp + CheapMod16(i +  2)*4)
 && ValidAddr(mem, sp + CheapMod16(i + 15)*4)

 && t3 == BitwiseXor(b, c)

    // Memory framing: We only touch the stack
 && (forall addr:word :: addr in orig_mem && (addr < sp || addr >= sp + 19*4) ==> addr in mem && mem[addr] == orig_mem[addr])
 && mem[sp + 16*4] == orig_mem[sp + 16*4]
 && mem[sp + 18*4] == orig_mem[sp + 18*4]

    // SHA semantics
 && SeqLength(current_trace.H) > 0
 && IsSHA256TraceReadyForStep(current_trace, i)
 && current_trace.M == orig_trace.M
 && current_trace.H == orig_trace.H
 && current_trace.W == orig_trace.W
 && (last(last(current_trace.atoh)) == 
        if i == 0 then 
            atoh_c(a, b, c, d, e, f, g, h)
        else 
            atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h))

    // t1 holds the current value of W
 && t1 == (if (i < 16) then input[i] else if i + 1 <= 64 then mem[sp + CheapMod16(i+1)*4] else last(current_trace.W)[i])

    // The first 16 values in W are the byte-swapped version of the input words
 && (forall j :: 0 <= j < 16 ==> last(current_trace.W)[j] == bswap32(input[j]))

    // All previous Ws are in memory where we expect them
 && (16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(current_trace.W)[j] == mem[sp + CheapMod16(j)*4]))
 && (i < 16 ==> (forall j :: 0 <= j < i ==> last(current_trace.W)[j] == mem[sp + j*4]))
 && (i < 15  ==> ValidAddr(mem, t4) && mem[t4] == input[i+1])
 && (i >= 15 ==> ValidAddr(mem, sp+CheapMod16(i+ 2)*4))
 && (i >= 15 ==> ValidAddr(mem, sp+CheapMod16(i+15)*4))

     // Updated input ptr
 && (if i < 16 then t4 == input_ptr + (i+1)*4         // Correctly advanced input ptr
     else mem[sp+17*4] == input_ptr + 4*16)             // We preserved the advanced input ptr on the stack

 && (i >= 16 ==> t4 == mem[sp + CheapMod16(i+14)*4])
}

#endverbatim

procedure {:refined} {:recursive} {:timeLimitMultiplier 2} Body_00_15UnrolledRecursive(
    inline n:int,
    inline i:int,
    inline perm:perm_index,
    ghost input_ptr:word,
    ghost orig_trace:SHA256Trace,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand t4:word,
    inout operand a:word,
    inout operand b:word,
    inout operand c:word,
    inout operand d:word,
    inout operand e:word,
    inout operand f:word,
    inout operand g:word,
    inout operand h:word
    ) returns (
    ghost trace_out:SHA256Trace
    )
  requires
    0 <= n <= 16;
    n == 16 - i;
    perm == OpaqueMod(i, 8);
  requires {:refined false}
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(GetReg(if Even(i) then 12 else 3));
    @t3 == OReg(GetReg(if Even(i) then  3 else 12));
    @t4 == OReg(R1);
    //@inp == OReg(R1);
    @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
    @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
    @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
    @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
    @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
    @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
    @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
    @h  == OReg(GetReg(4+ApplyPerm(7, perm)));
  requires
    Body_00_15LoopStateInvariantBreakdown(mem, mem, input_ptr, orig_trace, trace_in, i, sp, globals, lr,
                                          t1, t2, t3, t4, input,
                                          a, b, c, d, e, f, g, h);
  reads
    sp; globals;
  modifies
    mem; lr;
  ensures
    let arr := seq8(a, b, c, d, e, f, g, h) in
        Body_00_15LoopStateInvariantBreakdown(old(mem), mem, input_ptr, orig_trace, trace_out, 16, sp, globals, lr,
                                              t1, if Even(n) then t2 else t3, if Even(n) then t3 else t2, t4, input,
                                              SelectPerm(arr, 0, perm), SelectPerm(arr, 1, perm), SelectPerm(arr, 2, perm),
                                              SelectPerm(arr, 3, perm), SelectPerm(arr, 4, perm), SelectPerm(arr, 5, perm),
                                              SelectPerm(arr, 6, perm), SelectPerm(arr, 7, perm));
{
    inline if (0 < n <= 16 && 0 <= i < 16) {
        assert OpaqueMod(i + 1, 8) == (if perm == 7 then 0 else perm + 1) by { reveal OpaqueMod; }
        ghost var trace_mid:SHA256Trace;
        trace_mid := Body_00_15(i, perm,
                                CheapMod16(i)*4, CheapMod16(i+2)*4, CheapMod16(i+15)*4,
                                input_ptr, trace_in, input,
                                t0, t1, t2, t3, t4,
                                a, b, c, d, e, f, g, h);
        trace_out := Body_00_15UnrolledRecursive(n-1, i+1, if perm == 7 then 0 else perm + 1,
                                                 input_ptr, orig_trace, trace_mid, input,
                                                 t0, t1, t3, t2, t4,
                                                 h, a, b, c, d, e, f, g);
    }
    else {
        assert OpaqueMod(i, 8) == 0 by { reveal OpaqueMod; }
        trace_out := trace_in;
    }
}

procedure {:refined} Body_00_15LoopUnrolled(
    ghost input_ptr:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    ) returns (
    ghost trace_out:SHA256Trace
    )
    requires Body_00_15LoopStateInvariantBreakdown(mem, mem, input_ptr, trace_in, trace_in, 0, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
    reads  sp; globals;
    modifies mem; lr; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12;
    ensures  Body_00_15LoopStateInvariantBreakdown(old(mem), mem, input_ptr, trace_in, trace_out, 16, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
{
    assert OpaqueMod(0, 8) == 0 by { reveal OpaqueMod; }
    trace_out := Body_00_15UnrolledRecursive(16, 0, 0, input_ptr, trace_in, trace_in, input,
                                             r0, r2, r12, r3, r1,
                                             r4, r5, r6, r7, r8, r9, r10, r11);
}



procedure {:refined} {:timeLimitMultiplier 3} Body_16_XX( 
    inline i:SHA_step,
    inline perm:perm_index,
    inline input_slot:word,
    inline input_slot_9:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand t4:word,
    inout operand a:word,
          operand b:word,
          operand c:word,
    inout operand d:word,
          operand e:word,
          operand f:word,
          operand g:word,
    inout operand h:word)

requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp, 19);
reads 
    sp; globals;
modifies 
    mem; lr;
requires {:refined false}
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(GetReg(if Even(i) then 12 else 3));
    @t3 == OReg(GetReg(if Even(i) then  3 else 12));
    @t4 == OReg(R1);
    @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
    @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
    @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
    @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
    @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
    @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
    @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
    @h  == OReg(GetReg(4+ApplyPerm(7, perm)));

requires
    i >= 16;
    input_slot == CheapMod16(i)*4;
    input_slot_9 == CheapMod16(i+9)*4;
    ValidAddr(mem, sp + input_slot);
    ValidAddr(mem, sp + input_slot_9); 

    // K table adjusted properly
    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
    AddressOfGlobal(K_SHA256s()) + 4*64 < 0x1_0000_0000;    // We won't wrap around while accessing K_SHA256s
    lr == AddressOfGlobal(K_SHA256s()) + 4*i;
    SeqLength(globals[K_SHA256s()]) == 256;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    SeqLength(input) == 16;

    ValidAddr(mem, sp + CheapMod16(i +  2)*4);
    ValidAddr(mem, sp + CheapMod16(i + 15)*4);

    t3 == BitwiseXor(b, c);

    // SHA semantics
    SeqLength(trace_in.H) > 0;
    IsSHA256TraceReadyForStep(trace_in, i);
    last(last(trace_in.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h);

    // The first 16 values in W are the byte-swapped version of the input words
    forall j :: 0 <= j < 16 ==> last(trace_in.W)[j] == bswap32(input[j]);

    // All previous Ws are in memory where we expect them
    16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(trace_in.W)[j] == mem[sp + CheapMod16(j)*4]);

    // t1 and t4 should already hold previous W values
    t1 == mem[sp + CheapMod16(i+1)*4];
    t4 == mem[sp + CheapMod16(i+14)*4];
ensures 
    t2 == BitwiseXor(a, b);
    lr == old(lr) + 4;
    t4 == mem[sp+CheapMod16(i + 15)*4];

    mem[sp+17*4] == old(mem[sp+17*4]);         // We preserved the input ptr on the stack

    // Memory framing: We only touch the stack
    forall addr:word :: old(mem)?[addr] && (addr < sp || addr >= sp + 19*4) ==> mem?[addr] && mem[addr] == old(mem)[addr];
    mem[sp + 16*4] == old(mem)[sp + 16*4];
    mem[sp + 18*4] == old(mem)[sp + 18*4];

    exists trace_out:SHA256Trace ::
        IsSHA256TraceReadyForStep(trace_out, i+1)
     && trace_out.M == trace_in.M
     && trace_out.H == trace_in.H
     && trace_out.W == trace_in.W
     // t1 holds the next value of W
     && t1 == (if i + 1 <= 64 then mem[sp + CheapMod16(i + 2)*4] else t1) 

     // Remaining Ws are laid out in memory
     && (i + 1 < 64 ==> (forall j :: i+1 - 16 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + CheapMod16(j)*4]))

     // The atohs almost match the outgoing variables
     //&& (let old_a := (if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2))) in
     && last(last(trace_out.atoh)) == atoh_c(BitwiseAdd32(h, t3), a, b, c, d, e, f, g);
{
    rMOVShift(t0, t1, RORShift(sigma0(0)));
    rADDWrap(a, a, t2);  // h+=Maj(a,b,c) from the past
    rMOVShift(t2, t4, RORShift(sigma1(0)));
    rEORShift(t0,t0,t1,RORShift(sigma0(1)));
    rEORShift(t2,t2,t4,RORShift(sigma1(1)));
    rEORShift(t0,t0,t1,LSRShift(sigma0(2)));     // sigma0(X[i+1])
    assert t0 == SSIG0(t1) by { reveal SSIG0; }

    rLDR(t1, sp, input_slot);
    rEORShift(t2,t2,t4, LSRShift(sigma1(2)));     // sigma1(X[i+14])
    assert t2 == SSIG1(t4) by { reveal SSIG1; }
    rLDR(t4, sp, input_slot_9);

    rADDWrap(t2,t2,t0);
    rEORShift(t0,e,e,RORShift(Sigma1(1)-Sigma1(0)));    // from BODY_00_15
    rADDWrap(t1,t1,t2);
    rEORShift(t0,t0,e,RORShift(Sigma1(2)-Sigma1(0)));  // Sigma1(e)  BP: Almost

    // Prove that we computed Sigma1(e) correctly:
    forall :: RotateRight(t0, Sigma1(0)) == BSIG1(e)
    {
        reveal BSIG1;
        lemma_BSIGOptimization(e, 6, 11, 25);
    }

    rADDWrap(t1,t1,t4);      // X[i]

    // From the spec (and PartialSHA256TraceHasCorrectWs):
    ghost var W := last(trace_in.W);
    assert TStep(i);
    assert W[i] == BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(SSIG1(W[i-2]), W[i-7]), SSIG0(W[i-15])), W[i-16]);
    assert t1 == W[i] by {
        lemma_BitwiseAdd32Associates4(SSIG1(W[i-2]), W[i-7], SSIG0(W[i-15]), W[i-16], t1);
    }

    ghost var mid_a := a;
    ghost var mid_t2 := t2;
    ghost var dummy_input_ptr:word;  // Body_00_15 only cares about the value for i < 16
    ghost var trace_out:SHA256Trace;
    trace_out := Body_00_15(i, perm, input_slot, CheapMod16(i + 2)*4, CheapMod16(i + 15)*4, 
                            dummy_input_ptr, trace_in, input,
                            t0, t1, t2, t3, t4, 
                            a, b, c, d, e, f, g, h);
    assert a == mid_a;
}

#verbatim

predicate {:opaque} Body_16_XXLoopStateInvariantBreakdown(
    orig_mem:memmap,
    mem:memmap,
    orig_trace:SHA256Trace,
    current_trace:SHA256Trace,
    i:int,
    sp:word,
    globals:map<operand,seq<word>>,
    lr:word,
    t1:word,
    t2:word,
    t3:word,
    t4:word,
    input:seq<word>,
    a:word, b:word, c:word, d:word, e:word, f:word, g:word, h:word
    )
{
    16 <= i <= 64
 && ValidAddrs(orig_mem, sp, 19)
 && ValidAddrs(mem, sp, 19)
 && ValidAddr(mem, sp + CheapMod16(i)*4)
 && ValidAddr(mem, sp + CheapMod16(i+9)*4)

    // K table adjusted properly
 && (i < 64 ==> ValidGlobalsAddr(globals, K_SHA256s().sym, lr))
 && K_SHA256s() in globals
 && AddressOfGlobal(K_SHA256s()) + 4*64 < 0x1_0000_0000    // We won't wrap around while accessing K_SHA256s
 && lr == AddressOfGlobal(K_SHA256s()) + 4*i
 && |globals[K_SHA256s()]| == 256
 && (forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j))

 && SeqLength(input) == 16

 && ValidAddr(mem, sp + CheapMod16(i +  2)*4)
 && ValidAddr(mem, sp + CheapMod16(i + 15)*4)

 && t3 == BitwiseXor(b, c)

    // Memory framing: We only touch the stack
 && (forall addr:word :: addr in orig_mem && (addr < sp || addr >= sp + 19*4) ==> addr in mem && mem[addr] == orig_mem[addr])
 && mem[sp + 16*4] == orig_mem[sp + 16*4]
 && mem[sp + 17*4] == orig_mem[sp + 17*4]   // We preserved the input ptr on the stack
 && mem[sp + 18*4] == orig_mem[sp + 18*4]

    // SHA semantics
 && SeqLength(current_trace.H) > 0
 && IsSHA256TraceReadyForStep(current_trace, i)
 && current_trace.M == orig_trace.M
 && current_trace.H == orig_trace.H
 && current_trace.W == orig_trace.W
 && last(last(current_trace.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h)

    // The first 16 values in W are the byte-swapped version of the input words
 && (forall j :: 0 <= j < 16 ==> last(current_trace.W)[j] == bswap32(input[j]))

    // All previous Ws are in memory where we expect them
 && (16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(current_trace.W)[j] == mem[sp + CheapMod16(j)*4]))

    // t1 and t4 should already hold previous W values
 && (i < 64 ==> t1 == mem[sp + CheapMod16(i+1)*4])
 && t4 == mem[sp + CheapMod16(i+14)*4]
}

#endverbatim

procedure {:refined} Body_16_XXWrap(
    inline i:SHA_step,
    inline perm:perm_index,
    inline input_slot:word,
    inline input_slot_9:word,
    ghost orig_mem:memmap,
    ghost orig_trace:SHA256Trace,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand t4:word,
    //inout operand inp:word,
    inout operand a:word,
          operand b:word,
          operand c:word,
    inout operand d:word,
          operand e:word,
          operand f:word,
          operand g:word,
    inout operand h:word)
    returns (ghost trace_out:SHA256Trace)
    reads
        sp; globals;
    modifies
        mem; lr;
    requires {:refined false}
        @t0 == OReg(R0);
        @t1 == OReg(R2);
        @t2 == OReg(GetReg(if Even(i) then 12 else 3));
        @t3 == OReg(GetReg(if Even(i) then  3 else 12));
        @t4 == OReg(R1);
        //@inp == OReg(R1);
        @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
        @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
        @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
        @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
        @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
        @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
        @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
        @h  == OReg(GetReg(4+ApplyPerm(7, perm)));
    requires
        input_slot == CheapMod16(i)*4;
        input_slot_9 == CheapMod16(i+9)*4;
    requires Body_16_XXLoopStateInvariantBreakdown(orig_mem, mem, orig_trace, trace_in, i, sp, globals, lr,
                                                   t1, t2, t3, t4, input,
                                                   a, b, c, d, e, f, g, h);
    ensures  Body_16_XXLoopStateInvariantBreakdown(orig_mem, mem, orig_trace, trace_out, i + 1, sp, globals, lr,
                                                   t1, t3, t2, t4, input,
                                                   h, a, b, c, d, e, f, g);
{
    reveal Body_16_XXLoopStateInvariantBreakdown;

    Body_16_XX(i, perm, input_slot, input_slot_9, trace_in, input,
        t0, t1, t2, t3, t4, a, b, c, d, e, f, g, h);

    exists trace_out_tmp:SHA256Trace ::
            IsSHA256TraceReadyForStep(trace_out_tmp, i+1)
         && trace_out_tmp.M == trace_in.M
         && trace_out_tmp.H == trace_in.H
         && trace_out_tmp.W == trace_in.W
         && t1 == (if i + 1 <= 64 then mem[sp + CheapMod16(i + 2)*4] else t1)
         && (i + 1 < 64 ==> (forall j :: i+1 - 16 <= j < i+1 ==> last(trace_out_tmp.W)[j] == mem[sp + CheapMod16(j)*4]))
         && last(last(trace_out_tmp.atoh)) == atoh_c(BitwiseAdd32(h, t3), a, b, c, d, e, f, g);

    trace_out := trace_out_tmp;
    assert Body_16_XXLoopStateInvariantBreakdown(old(mem), mem, trace_in, trace_out, i + 1, sp, globals, lr,
                                                       t1, t3, t2, t4, input,
                                                       h, a, b, c, d, e, f, g);
}

procedure {:refined}{:recursive}{:timeLimitMultiplier 2} Body_16_XXUnroller(
    inline n:nat,
    inline i:int,
    inline perm:perm_index,
    inline input_slot:word,
    inline input_slot_9:word,
    ghost orig_mem:memmap,
    ghost orig_trace:SHA256Trace,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand t4:word,
    inout operand a:word,
    inout operand b:word,
    inout operand c:word,
    inout operand d:word,
    inout operand e:word,
    inout operand f:word,
    inout operand g:word,
    inout operand h:word)
    returns (ghost trace_out:SHA256Trace)
    reads
        sp; globals;
    modifies
        mem; lr;
    requires {:refined false}
        @t0 == OReg(R0);
        @t1 == OReg(R2);
        @t2 == OReg(GetReg(if Even(i) then 12 else 3));
        @t3 == OReg(GetReg(if Even(i) then  3 else 12));
        @t4 == OReg(R1);
        @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
        @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
        @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
        @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
        @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
        @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
        @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
        @h  == OReg(GetReg(4+ApplyPerm(7, perm)));
        0 <= i <= 64;
        n == 64 - i;
    requires
        0 <= i <= 64;
        n == 64 - i;
        perm == OpaqueMod(i, 8);
        input_slot == CheapMod16(i)*4;
        input_slot_9 == CheapMod16(i+9)*4;
        Body_16_XXLoopStateInvariantBreakdown(orig_mem, mem, orig_trace, trace_in, i, sp, globals, lr,
            t1, t2, t3, t4, input, a, b, c, d, e, f, g, h);
    ensures
        let arr := seq8(a, b, c, d, e, f, g, h) in
            Body_16_XXLoopStateInvariantBreakdown(orig_mem, mem, orig_trace, trace_out, 64, sp, globals, lr,
                t1, if Even(i) then t2 else t3, if Even(i) then t3 else t2, t4, input,
                SelectPerm(arr, 0, perm), SelectPerm(arr, 1, perm), SelectPerm(arr, 2, perm), SelectPerm(arr, 3, perm),
                SelectPerm(arr, 4, perm), SelectPerm(arr, 5, perm), SelectPerm(arr, 6, perm), SelectPerm(arr, 7, perm));
{
    inline if (n > 0 && 0 <= i < 64) {
        assert OpaqueMod(i + 1, 8) == (if perm == 7 then 0 else perm + 1) by { reveal OpaqueMod; }
        trace_out := Body_16_XXWrap(i, perm, input_slot, input_slot_9, orig_mem, orig_trace, trace_in, input,
            t0, t1, t2, t3, t4, a, b, c, d, e, f, g, h);
        trace_out := Body_16_XXUnroller(n - 1, i + 1, if perm == 7 then 0 else perm + 1, CheapMod16(i + 1) * 4, CheapMod16(i + 10) * 4,
            orig_mem, orig_trace, trace_out, input,
            t0, t1, t3, t2, t4, h, a, b, c, d, e, f, g);
    } else {
        assert OpaqueMod(i, 8) == 0 by { reveal OpaqueMod; }
        trace_out := trace_in;
    }
}

procedure {:refined} Body_16_XXLoopUnrolled(
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
    requires Body_16_XXLoopStateInvariantBreakdown(mem, mem, trace_in, trace_in, 16, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
    reads  sp; globals;
    modifies mem; lr; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12;
    ensures  exists trace_out ::
             Body_16_XXLoopStateInvariantBreakdown(old(mem), mem, trace_in, trace_out, 64, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
{
    assert OpaqueMod(16, 8) == 0 by { reveal OpaqueMod; }
    ghost var trace_out;
    ghost var orig_mem := mem;
    trace_out := Body_16_XXUnroller(48, 16, 0, CheapMod16(16) * 4, CheapMod16(16 + 9) * 4,
        orig_mem, trace_in, trace_in, input,
        r0, r2, r12, r3, r1, r4, r5, r6, r7, r8, r9, r10, r11);
}

procedure {:refined} {:timeLimitMultiplier 2} update_Hs(
    ghost base_ptr:word,
    inout operand t0:word,
    inout operand t1:word,
    inout operand t2:word,
    inout operand t3:word,
    inout operand a:word,
    inout operand b:word,
    inout operand c:word,
    inout operand d:word,
    inout operand e:word,
    inout operand f:word,
    inout operand g:word,
    inout operand h:word
    )
requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp, 19);

    base_ptr == mem[sp + 16*4];

    // Base_ptr doesn't alias the stack
    base_ptr + 32 < sp || base_ptr > sp + 19*4;

    ValidAddrs(mem, base_ptr, 8);
requires {:refined false}   // Using this style so I can give explicit names to all the registers.  Less confusing this way.
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(R12);
    @t3 == OReg(R3);
    @a  == OReg(R4);
    @b  == OReg(R5);
    @c  == OReg(R6);
    @d  == OReg(R7);
    @e  == OReg(R8);
    @f  == OReg(R9);
    @g  == OReg(R10);
    @h  == OReg(R11);
reads
    sp;
modifies 
    mem; 
ensures
    // Memory framing: We only touch 8 bytes pointed to by the base_ptr
    forall addr:word :: old(mem)?[addr] && (addr < base_ptr || addr >= base_ptr + 8*4)
                    ==> mem?[addr] && mem[addr] == old(mem)[addr];
    mem[base_ptr +  0*4] == a == BitwiseAdd32(old(mem)[base_ptr +  0*4], old(a));
    mem[base_ptr +  1*4] == b == BitwiseAdd32(old(mem)[base_ptr +  1*4], old(b));
    mem[base_ptr +  2*4] == c == BitwiseAdd32(old(mem)[base_ptr +  2*4], old(c));
    mem[base_ptr +  3*4] == d == BitwiseAdd32(old(mem)[base_ptr +  3*4], old(d));
    mem[base_ptr +  4*4] == e == BitwiseAdd32(old(mem)[base_ptr +  4*4], old(e));
    mem[base_ptr +  5*4] == f == BitwiseAdd32(old(mem)[base_ptr +  5*4], old(f));
    mem[base_ptr +  6*4] == g == BitwiseAdd32(old(mem)[base_ptr +  6*4], old(g));
    mem[base_ptr +  7*4] == h == BitwiseAdd32(old(mem)[base_ptr +  7*4], old(h));
{
    // Load the ctx pointer that holds the Hs
    rLDR(t3, sp, 64);
    assert t3 == base_ptr;
    rLDR(t0, t3, 0);
    rLDR(t1, t3, 4);
    rLDR(t2, t3, 8);
    rADDWrap(a, a, t0);
    rLDR(t0, t3, 12);
    rADDWrap(b, b, t1);
    rLDR(t1, t3, 16);
    rADDWrap(c, c, t2);
    rLDR(t2,t3,20);
    rADDWrap(d,d,t0);
    rLDR(t0,t3,24);
    rADDWrap(e,e,t1);
    rLDR(t1,t3,28);
    rADDWrap(f,f,t2);
    rADDWrap(g,g,t0);
    rADDWrap(h,h,t1);

    // TODO: OpenSSL does this in a single call to: stmia $t3,{$A,$B,$C,$D,$E,$F,$G,$H}
    rSTR(a, t3,  0); 
    //assert ValidAddr(old(mem), t3 + 4);      // OBSERVE
    rSTR(b, t3,  4); 
    //assert ValidAddr(old(mem), t3 + 8);      // OBSERVE
    rSTR(c, t3,  8); 
    //assert ValidAddr(old(mem), t3 + 12);     // OBSERVE
    rSTR(d, t3, 12); 
    //assert ValidAddr(old(mem), t3 + 16);     // OBSERVE
    rSTR(e, t3, 16); 
    //assert ValidAddr(old(mem), t3 + 20);     // OBSERVE
    rSTR(f, t3, 20); 
    //assert ValidAddr(old(mem), t3 + 24);     // OBSERVE
    rSTR(g, t3, 24); 
    //assert ValidAddr(old(mem), t3 + 28);     // OBSERVE
    rSTR(h, t3, 28); 
}

procedure {:refined} {:timeLimitMultiplier 3} sha256_one_block(
    ghost base_ptr:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp, 19);

    base_ptr == mem[sp + 16*4];

    // Base_ptr doesn't alias the stack
    base_ptr + 32 < sp || base_ptr > sp + 19*4;

    // Stack slot 16 holds a pointer to a valid region of memory with 8 words of data in it
    ValidAddrs(mem, base_ptr, 8);

requires
    // SHA semantics
    IsCompleteSHA256Trace(trace_in);
    SHA256TraceIsCorrect(trace_in);
    
    // K table adjusted properly
    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
    globals?[K_SHA256s()];
    AddressOfGlobal(K_SHA256s()) + 256 < 0x1_0000_0000;
    lr == AddressOfGlobal(K_SHA256s());
    SeqLength(globals[K_SHA256s()]) == 256;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    let t0 := r0 in
    let t1 := r2 in
    let t2 := r12 in
    let t3 := r3 in
    let t4 := r1 in
    let a := r4 in
    let b := r5 in
    let c := r6 in
    let d := r7 in
    let e := r8 in
    let f := r9 in
    let g := r10 in
    let h := r11 in

    let ctx := r0 in
    let input_ptr := r1 in
    let num_blocks := r2 in // Number of 64-byte blocks to process
        last(trace_in.H)[0] == mem[base_ptr + 0*4] == a
     && last(trace_in.H)[1] == mem[base_ptr + 1*4] == b
     && last(trace_in.H)[2] == mem[base_ptr + 2*4] == c
     && last(trace_in.H)[3] == mem[base_ptr + 3*4] == d
     && last(trace_in.H)[4] == mem[base_ptr + 4*4] == e
     && last(trace_in.H)[5] == mem[base_ptr + 5*4] == f
     && last(trace_in.H)[6] == mem[base_ptr + 6*4] == g
     && last(trace_in.H)[7] == mem[base_ptr + 7*4] == h

     // Ghost input matches in-memory input
     && SeqLength(input) == 16
     && (input_ptr + 16*4) < 0x1_0000_0000
     && (input_ptr + 16*4 < sp || sp + 19*4 <= input_ptr)    // input_ptr doesn't alias the stack
     && ValidAddrs(mem, input_ptr, 16)
     && (forall j { mem?[input_ptr+j*4] } :: 0 <= j < 16 ==> mem[input_ptr + j*4] == input[j])
     ;
reads
    sp; globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; lr;
ensures
    // Memory framing: We only touch the stack and 8 bytes pointed to by the base_ptr
    forall addr:word :: old(mem)?[addr] && (addr < sp || addr >= sp + 19*4) && (addr < base_ptr || addr >= base_ptr + 8*4)
                    ==> mem?[addr] && mem[addr] == old(mem)[addr];

    lr == AddressOfGlobal(K_SHA256s()) + 256;

    mem[sp + 16*4] == old(mem)[sp + 16*4];
    mem[sp + 17*4] == old(r1) + 64;
    mem[sp + 18*4] == old(mem)[sp + 18*4];

    exists trace_out:SHA256Trace ::
           IsCompleteSHA256Trace(trace_out)
        && SHA256TraceIsCorrect(trace_out)
        && trace_out.M == trace_in.M + seq(bswap32_seq(input))
        && mem[base_ptr + 0*4] ==  r4 == last(trace_out.H)[0]
        && mem[base_ptr + 1*4] ==  r5 == last(trace_out.H)[1]
        && mem[base_ptr + 2*4] ==  r6 == last(trace_out.H)[2]
        && mem[base_ptr + 3*4] ==  r7 == last(trace_out.H)[3]
        && mem[base_ptr + 4*4] ==  r8 == last(trace_out.H)[4]
        && mem[base_ptr + 5*4] ==  r9 == last(trace_out.H)[5]
        && mem[base_ptr + 6*4] == r10 == last(trace_out.H)[6]
        && mem[base_ptr + 7*4] == r11 == last(trace_out.H)[7];
{
    // Prepare the incoming trace by incorporating the input we're about to digest
    ghost var bswapped_input := bswap32_seq(input);
    ghost var new_Ws := ComputeWs(bswapped_input);
    ghost var init_atoh := atoh_c(r4, r5, r6, r7, r8, r9, r10, r11);
    ghost var new_trace_in := lemma_SHA256DigestOneBlockHelper1(trace_in, new_Ws, init_atoh, bswapped_input);

    forall j :| 0 <= j < 16 :: last(new_trace_in.W)[j] == bswap32(input[j])
        { assert TStep(j); }
    assert IsSHA256TraceReadyForStep(new_trace_in, 0);

    // Set up the initial conditions for BODY_00_15
    assert ValidAddr(mem, r1 + 0*4);    // OBSERVE that r1 aka t1 is a ValidAddr
    rLDR(r2, r1, 0);        // t1 <- input[0]
    assert r2 == input[0];
    rADDWrap(r1, r1, 4);        // TODO: OpenSSL does this with a single LDR instruction
    rEOR(r3, r5, r6);       // t3 <- B xor C  "@magic"
    //rEOR(r12, r12, r12);    // Note: OpenSSL includes this unnecessarily, since for i=0, we clobber r12
    //assert r12 == 0 by { lemma_XorSelfIsZero(); }

    assert r1 /*aka t4*/ == old(r1) + 1 * 4;    // OBSERVE that t4 is a ValidAddr
    ghost var input_ptr := old(r1);      // Avoid Spartan mis-capture

    assert Body_00_15LoopStateInvariantBreakdown(mem, mem, input_ptr, new_trace_in, new_trace_in, 0, sp, globals, lr, 
                                                 r2, r12, r3, r1, input,
                                                 r4, r5, r6, r7, r8, r9, r10, r11);

    ghost var trace_00_15:SHA256Trace;
    trace_00_15 := Body_00_15LoopUnrolled(input_ptr, new_trace_in, input);

    ghost var mid_mem := mem;
    reveal Body_16_XXLoopStateInvariantBreakdown;
    Body_16_XXLoopUnrolled(trace_00_15, input);
    
    exists trace_16_XX :: 
             Body_16_XXLoopStateInvariantBreakdown(mid_mem, mem, trace_00_15, trace_16_XX, 64, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
    rADDWrap(r4, r4, r12);      // Add final Maj into a

    forall addr :| base_ptr <= addr < base_ptr + 8 * 4 && (addr - base_ptr) % 4 == 0 
        :: ValidAddr(mem, addr)
    {
        assert old(mem)?[addr];
    }
    update_Hs(base_ptr, r0, r2, r12, r3, r4, r5, r6, r7, r8, r9, r10, r11);

    ghost var old_H := seq( old(mem)[base_ptr +  0],
                            old(mem)[base_ptr +  4],
                            old(mem)[base_ptr +  8],
                            old(mem)[base_ptr + 12],
                            old(mem)[base_ptr + 16],
                            old(mem)[base_ptr + 20],
                            old(mem)[base_ptr + 24],
                            old(mem)[base_ptr + 28]);
    ghost var new_H := seq( mem[base_ptr +  0],
                            mem[base_ptr +  4],
                            mem[base_ptr +  8],
                            mem[base_ptr + 12],
                            mem[base_ptr + 16],
                            mem[base_ptr + 20],
                            mem[base_ptr + 24],
                            mem[base_ptr + 28]);
    ghost var trace_out := lemma_SHA256DigestOneBlockHelper2(trace_16_XX, old_H, new_H);
}

procedure {:refined} sha256_loop_body(
    ghost ctx_ptr:word,
    ghost input_ptr:word,
    ghost input:seq(word),
    ghost num_blocks:nat,
    ghost old_M_length:nat,
    ghost old_mem:memmap,
    ghost block:nat
    )
requires block < num_blocks;
requires exists trace_in ::
         BlockInvariant(trace_in, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, block);
reads
    sp; globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; lr;
ensures exists trace_out ::
        BlockInvariant(trace_out, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, block+1);
{
    ghost var block_input := SeqSlice(input, block*16, (block+1)*16);

    ghost var current_input_ptr := r1;  // == input_ptr + block*16*4
    forall j :| 0 <= j < 16 :: ValidAddr(mem, current_input_ptr + j*4)
                            && mem[current_input_ptr + j*4] == block_input[j]
    {
        assert current_input_ptr + j*4 == input_ptr + (block*16+j)*4;
        assert ValidAddr(mem, current_input_ptr + j*4);
    }
    ghost var prev_mem := mem;
    exists trace_in ::
         BlockInvariant(trace_in, input, globals, old_M_length, mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, block);
    sha256_one_block(ctx_ptr, trace_in, block_input);
    exists trace_out:SHA256Trace ::
           IsCompleteSHA256Trace(trace_out)
        && SHA256TraceIsCorrect(trace_out)
        && trace_out.M == trace_in.M + seq(bswap32_seq(block_input))
        && mem[ctx_ptr + 0*4] ==  r4 == last(trace_out.H)[0]
        && mem[ctx_ptr + 1*4] ==  r5 == last(trace_out.H)[1]
        && mem[ctx_ptr + 2*4] ==  r6 == last(trace_out.H)[2]
        && mem[ctx_ptr + 3*4] ==  r7 == last(trace_out.H)[3]
        && mem[ctx_ptr + 4*4] ==  r8 == last(trace_out.H)[4]
        && mem[ctx_ptr + 5*4] ==  r9 == last(trace_out.H)[5]
        && mem[ctx_ptr + 6*4] == r10 == last(trace_out.H)[6]
        && mem[ctx_ptr + 7*4] == r11 == last(trace_out.H)[7];

    assert 68 == 17*4;
    rLDR(r1, sp, 68);  // Reload input_ptr
    assert 72 == 18*4; // Reload end_ptr
    rLDR(r12, sp, 72); // Reload input_ptr
    rSUB(lr, lr, 256); // Reset lr

    forall addr :| input_ptr <= addr < input_ptr + (num_blocks*16)*4 && (addr - input_ptr) % 4 == 0
                :: ValidAddr(mem, addr)
    {
        assert ValidAddr(old(mem), addr);
    }
    assert ValidAddrs(mem, input_ptr, num_blocks*16);

    forall j :| 0 <= j < num_blocks * 16 :: mem[input_ptr + j*4] == input[j]
    {
        assert old(mem)?[input_ptr + j*4];
    }

    assert BlockInvariant(trace_out, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                          r4, r5, r6, r7, r8, r9, r10, r11,
                          input_ptr, ctx_ptr, num_blocks, block+1);
}


procedure {:refined} sha256_loop(
    ghost ctx_ptr:word,
    ghost input_ptr:word,
    ghost input:seq(word),
    ghost num_blocks:nat,
    ghost old_M_length:nat,
    ghost old_mem:memmap
    )
requires exists trace_in ::
         BlockInvariant(trace_in, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, 0);
reads
    sp; globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; lr;
ensures exists trace_out ::
        BlockInvariant(trace_out, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, num_blocks);
{
    ghost var block:nat := 0;
    while (r1 < r12)
        invariant
            exists trace :: 
                BlockInvariant(trace, input, globals, old_M_length, old_mem, mem, sp, lr, r1, r12,
                               r4, r5, r6, r7, r8, r9, r10, r11,
                               input_ptr, ctx_ptr, num_blocks, block);
         decreases r12 - r1;
    {
        sha256_loop_body(ctx_ptr, input_ptr, input, num_blocks, old_M_length, old_mem, block);
        block := block + 1;
    }
}

// Core implementation that does the real work
procedure {:refined} {:timeLimitMultiplier 2} sha256_block_data_order_inner(
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp, 19);
    
requires
    IsCompleteSHA256Trace(trace_in);
    SHA256TraceIsCorrect(trace_in);

    // K table is valid
    ValidGlobals(globals);
    ValidGlobal(K_SHA256s());
    SeqLength(globals[K_SHA256s()]) == 256;
    AddressOfGlobal(K_SHA256s()) + 256 < 0x1_0000_0000;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    let ctx := r0 in
    let input_ptr := r1 in
    let num_blocks := r2 in // Number of 64-byte blocks to process

     // Old H values are laid out in memory pointed at by ctx
        ValidAddrs(mem, ctx, 8)
     && last(trace_in.H)[0] == mem[ctx + 0*4]
     && last(trace_in.H)[1] == mem[ctx + 1*4]
     && last(trace_in.H)[2] == mem[ctx + 2*4]
     && last(trace_in.H)[3] == mem[ctx + 3*4]
     && last(trace_in.H)[4] == mem[ctx + 4*4]
     && last(trace_in.H)[5] == mem[ctx + 5*4]
     && last(trace_in.H)[6] == mem[ctx + 6*4]
     && last(trace_in.H)[7] == mem[ctx + 7*4]

     // Ghost input matches in-memory input
     && SeqLength(input) == num_blocks*16
     && input_ptr + num_blocks*16*4 < 0x1_0000_0000
     && ValidAddrs(mem, input_ptr, num_blocks*16)
     && (forall j { mem?[input_ptr+j*4] } :: 0 <= j < num_blocks*16 ==> mem[input_ptr + j*4] == input[j]
         )

     // Anti-aliasing
     && (ctx + 32 < input_ptr || ctx > input_ptr + num_blocks*16*4)    // input_ptr != ctx
     && (ctx + 32 < sp || ctx > sp + 19*4)                             // ctx != sp
     && (input_ptr + num_blocks*16*4 < sp || input_ptr >= sp + 19*4);  // input_ptr != sp

reads
    sp; globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; lr;
ensures
    // Memory framing:  We only touch the stack and 8 bytes pointed to by ctx_ptr
    forall addr:word :: old(mem)?[addr] && (addr < sp || addr >= sp + 19 * 4) 
                                        && (addr < old(r0) || addr >= old(r0) + 8 * 4) 
                            ==> mem?[addr] && old(mem)[addr] == mem[addr];
    forall j {ValidAddr(mem, old(r0)+j*4)} { mem?[old(r0)+j*4] } :: 0 <= j < 8 ==> ValidAddr(mem, old(r0) + j*4);

    exists trace_out ::
           IsCompleteSHA256Trace(trace_out)
        && SHA256TraceIsCorrect(trace_out)
        && SeqLength(trace_out.M) == SeqLength(trace_in.M) + old(r2)
        && (forall i :: 0 <= i < old(r2) 
             ==> trace_out.M[SeqLength(trace_in.M) + i] == bswap32_seq(SeqSlice(input, i*16, (i+1)*16))) 
        && last(trace_out.H)[0] == mem[old(r0) + 0*4]
        && last(trace_out.H)[1] == mem[old(r0) + 1*4]
        && last(trace_out.H)[2] == mem[old(r0) + 2*4]
        && last(trace_out.H)[3] == mem[old(r0) + 3*4]
        && last(trace_out.H)[4] == mem[old(r0) + 4*4]
        && last(trace_out.H)[5] == mem[old(r0) + 5*4]
        && last(trace_out.H)[6] == mem[old(r0) + 6*4]
        && last(trace_out.H)[7] == mem[old(r0) + 7*4]
        ;

{
    rLDRglobaladdr(lr, K_SHA256s().sym);

    ghost var ctx_ptr := r0;
    ghost var input_ptr := r1;
    ghost var num_blocks := r2;

    rADDWrapShift(r2, r1, r2, LSLShift(6)); // r2 <- input_ptr + 64 * num_blocks
    assert r2 == r1 + 64 * num_blocks by {
        lemma_ShiftsAdd(num_blocks, 2, 4);
        lemma_LeftShift2(num_blocks);
        lemma_LeftShift4(num_blocks*4);
    }

    // Save some of the initial state away.  We'll need it later.
    assert 64 == 16*4;
    rSTR(r0, sp, 64);
    assert 72 == 18*4;
    assert ValidAddr(old(mem), sp + 18*4);      // OBSERVE
    rSTR(r2, sp, 72);
    // Move end_ptr into r12 to satisfy the BlockInvariant. 
    // Note: OpenSSL appears to avoid this by assuming num_blocks > 0
    rMOV(r12, r2);  

    // Lots of OBSERVE
    assert ValidAddr(old(mem), r0 + 0*4);
    assert ValidAddr(old(mem), r0 + 1*4);
    assert ValidAddr(old(mem), r0 + 2*4);
    assert ValidAddr(old(mem), r0 + 3*4);
    assert ValidAddr(old(mem), r0 + 4*4);
    assert ValidAddr(old(mem), r0 + 5*4);
    assert ValidAddr(old(mem), r0 + 6*4);
    assert ValidAddr(old(mem), r0 + 7*4);
    // Load a - h values into registers
    rLDR(r4, r0, 0);
    rLDR(r5, r0, 4);
    rLDR(r6, r0, 8);
    rLDR(r7, r0, 12);
    rLDR(r8, r0, 16);
    rLDR(r9, r0, 20);
    rLDR(r10, r0, 24);
    rLDR(r11, r0, 28);

    forall j :| 0 <= j < 19 :: ValidAddr(mem, sp + j*4)
    {
        assert ValidAddr(old(mem), sp + j*4);
    }


    forall addr :| input_ptr <= addr < input_ptr + (num_blocks*16)*4 && (addr - input_ptr) % 4 == 0
        :: ValidAddr(mem, addr)
    {
        assert ValidAddr(old(mem), addr);
    }
    assert ValidAddrs(mem, input_ptr, num_blocks * 16);



    forall j :| 0 <= j < num_blocks * 16 :: mem[input_ptr + j*4] == input[j]
    {
        assert ValidAddr(old(mem), input_ptr + j*4);
    }

    // OBSERVE
    ghost var prev_mem := mem;  // Avoid Spartan mis-capture
    ghost var len_M := SeqLength(trace_in.M);   
    assert BlockInvariant(trace_in, input, globals, len_M, prev_mem, mem, sp, lr, r1, r12,
                          r4, r5, r6, r7, r8, r9, r10, r11,
                          input_ptr, ctx_ptr, num_blocks, 0);
    sha256_loop(ctx_ptr, input_ptr, input, num_blocks, len_M, prev_mem);
    exists trace_out ::
        BlockInvariant(trace_out, input, globals, len_M, prev_mem, mem, sp, lr, r1, r12,
                        r4, r5, r6, r7, r8, r9, r10, r11,
                        input_ptr, ctx_ptr, num_blocks, num_blocks);
    assert IsCompleteSHA256Trace(trace_out);
}

procedure {:refined} scrub_stack()
requires/ensures
    ValidAddrs(mem, sp, 29);  // Stack is accessible
reads r0; sp;
modifies mem;
ensures
    forall addr :: old(mem)?[addr] && (addr < sp || addr >= sp + 116)
                ==> mem?[addr] && old(mem)[addr] == mem[addr];
{
    rSTR(r0, sp, 0);
    rSTR(r0, sp, 4);
    rSTR(r0, sp, 8);
    rSTR(r0, sp, 12);
    rSTR(r0, sp, 16);
    rSTR(r0, sp, 20);
    rSTR(r0, sp, 24);
    rSTR(r0, sp, 28);
    rSTR(r0, sp, 32);
    rSTR(r0, sp, 36);
    rSTR(r0, sp, 40);
    rSTR(r0, sp, 44);
    rSTR(r0, sp, 48);
    rSTR(r0, sp, 52);
    rSTR(r0, sp, 56);
    rSTR(r0, sp, 60);
    rSTR(r0, sp, 64);
    rSTR(r0, sp, 68);
    rSTR(r0, sp, 72);
    rSTR(r0, sp, 76);
    rSTR(r0, sp, 80);
    rSTR(r0, sp, 84);
    rSTR(r0, sp, 88);
    rSTR(r0, sp, 92);
    rSTR(r0, sp, 96);
    rSTR(r0, sp, 100);
    rSTR(r0, sp, 104);
    rSTR(r0, sp, 108);
    rSTR(r0, sp, 112);
}

// Wrapper around the inner version that conforms to the calling convention
procedure {:refined} {:timeLimitMultiplier 3} sha256_block_data_order(
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
requires/ensures
    // Stack is accessible
    ValidAddrs(mem, sp-116, 29);
    
requires
    IsCompleteSHA256Trace(trace_in);
    SHA256TraceIsCorrect(trace_in);

    sp >= 116;

    // K table is valid
    ValidGlobals(globals);
    ValidGlobal(K_SHA256s());
    SeqLength(globals[K_SHA256s()]) == 256;
    AddressOfGlobal(K_SHA256s()) + 256 < 0x1_0000_0000;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    let ctx := r0 in
    let input_ptr := r1 in
    let num_blocks := r2 in // Number of 64-byte blocks to process

     // Old H values are laid out in memory pointed at by ctx
        ValidAddrs(mem, ctx, 8)
     && last(trace_in.H)[0] == mem[ctx + 0*4]
     && last(trace_in.H)[1] == mem[ctx + 1*4]
     && last(trace_in.H)[2] == mem[ctx + 2*4]
     && last(trace_in.H)[3] == mem[ctx + 3*4]
     && last(trace_in.H)[4] == mem[ctx + 4*4]
     && last(trace_in.H)[5] == mem[ctx + 5*4]
     && last(trace_in.H)[6] == mem[ctx + 6*4]
     && last(trace_in.H)[7] == mem[ctx + 7*4]

     // Ghost input matches in-memory input
     && SeqLength(input) == num_blocks*16
     && input_ptr + num_blocks*16*4 < 0x1_0000_0000
     && ValidAddrs(mem, input_ptr, num_blocks*16)
     && (forall j { mem?[input_ptr+j*4] } :: 0 <= j < num_blocks*16 ==> mem[input_ptr + j*4] == input[j])

     // Anti-aliasing
     && (ctx + 32 < input_ptr || ctx > input_ptr + num_blocks*16*4)    // input_ptr != ctx
     && (ctx + 32 < sp - 116 || ctx > sp)                              // ctx != sp
     && (input_ptr + num_blocks*16*4 < sp - 116 || input_ptr >= sp);   // input_ptr != sp

reads
    globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; sp; lr;
ensures
    // Memory framing:  We only touch the stack and 8 bytes pointed to by ctx_ptr
    forall addr:word :: old(mem)?[addr] && (addr < sp - 116 || addr >= sp) 
                                        && (addr < old(r0) || addr >= old(r0) + 8 * 4) 
                            ==> mem?[addr] && old(mem)[addr] == mem[addr];
    ValidAddrs(mem, old(r0), 8);

    // Calling convention
    r4 == old(r4);
    r5 == old(r5);
    r6 == old(r6);
    r7 == old(r7);
    r8 == old(r8);
    r9 == old(r9);
    r10== old(r10);
    r11== old(r11);
    sp == old(sp);  
    lr == old(lr);

    // SHA results
    exists trace_out ::
           IsCompleteSHA256Trace(trace_out)
        && SHA256TraceIsCorrect(trace_out)
        && SeqLength(trace_out.M) == SeqLength(trace_in.M) + old(r2)
        && (forall i :: 0 <= i < old(r2) 
             ==> trace_out.M[SeqLength(trace_in.M) + i] == bswap32_seq(SeqSlice(input, i*16, (i+1)*16))) 
        && last(trace_out.H)[0] == mem[old(r0) + 0*4]
        && last(trace_out.H)[1] == mem[old(r0) + 1*4]
        && last(trace_out.H)[2] == mem[old(r0) + 2*4]
        && last(trace_out.H)[3] == mem[old(r0) + 3*4]
        && last(trace_out.H)[4] == mem[old(r0) + 4*4]
        && last(trace_out.H)[5] == mem[old(r0) + 5*4]
        && last(trace_out.H)[6] == mem[old(r0) + 6*4]
        && last(trace_out.H)[7] == mem[old(r0) + 7*4]
        ;
{
    // We need 10 slots to save/restore registers, and then the inner routine needs 19 slots for scratch space
    rSUB(sp, sp, 116);

    // Save nonvolatile registers
    assert 112 == 28*4;
    rSTR(lr,  sp, 112);
    assert 108 == 27*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 27*4);
    rSTR(r4,  sp, 108);
    assert 104 == 26*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 26*4);
    rSTR(r5,  sp, 104);
    assert 100 == 25*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 25*4);
    rSTR(r6,  sp, 100);
    assert 96 == 24*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 24*4);
    rSTR(r7,  sp, 96);
    assert 92 == 23*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 23*4);
    rSTR(r8,  sp, 92);
    assert 88 == 22*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 22*4);
    rSTR(r9,  sp, 88);
    assert 84 == 21*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 21*4);
    rSTR(r10, sp, 84);
    assert 80 == 20*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 20*4);
    rSTR(r11, sp, 80);
    assert 76 == 19*4;
    assert ValidAddr(old(mem), old(sp) - 116 + 19*4);
    rSTR(r12, sp, 76);

    // Prove the stack is accessible (sigh)
    forall j {ValidAddr(mem, sp+j*4)} { mem?[sp+j*4] } :| 0 <= j < 19 :: ValidAddr(mem, sp + j*4)
    {
        assert ValidAddr(old(mem), old(sp) - 116 + j*4);
    }

    // Prove that ctx is still accessible (sigh)
    forall addr :| r0 <= addr < r0 + 8 * 4 && (addr - r0) % 4 == 0
        :: ValidAddr(mem, addr)
    {
        assert old(mem)?[addr];
    }

    // Prove that input is still accessible (sigh)
    ghost var num_blocks := r2;
    forall addr :| r1 <= addr < r1 + (num_blocks*16) * 4 && (addr - r1) % 4 == 0
        :: ValidAddr(mem, addr)
    {
        assert old(mem)?[addr];
    }

    sha256_block_data_order_inner(trace_in, input);

    // Restore the nonvolatile registers
    rLDR(lr,  sp, 112);
    rLDR(r4,  sp, 108);
    rLDR(r5,  sp, 104);
    rLDR(r6,  sp, 100);
    rLDR(r7,  sp, 96);
    rLDR(r8,  sp, 92);
    rLDR(r9,  sp, 88);
    rLDR(r10, sp, 84);
    rLDR(r11, sp, 80);
    rLDR(r12, sp, 76);

    // Restore the stack pointer
    rADDWrap(sp, sp, 116);
}

//#verbatim
//
//method Main()
//{
//    printHeader();
//    var n := printFunction("sha256_block_data_order", sp_code_sha256_block_data_order(), 0);
//    print "  BX lr"; nl();
//    printBss(KomGlobalDecls());
//    printFooter();
//}
//
//#endverbatim

#verbatim
} // end module sha256_spartan
#endverbatim

