///////////////////////////////////////////////////
//
//  Based on sha256-armv4.pl form OpenSSL 1.0.2j
//
///////////////////////////////////////////////////


#verbatim
module sha256_refined_Body_00_15 {
import opened sha256_refined_Body_00_15_ARMdecls = ARMdecls
import opened sha256_refined_Body_00_15_ARMspartan = ARMspartan
import opened sha256_refined_Body_00_15_sha256_i = sha256_i
import opened sha256_refined_Body_00_15_sha256_refined_helpers_i = sha256_refined_helpers_i

function method Sigma0(i:int) : word
    requires 0 <= i < 3;
{
    [2, 13, 22][i]
}

function method Sigma1(i:int) : word
    requires 0 <= i < 3;
{
    [6, 11, 25][i]
}

function method sigma0(i:int) : word
    requires 0 <= i < 3;
{
    [7, 18, 3][i]
}

function method sigma1(i:int) : word
    requires 0 <= i < 3;
{
    [17, 19, 10][i]
}

type SHA_step = i | 0 <= i < 64
type perm_index = i | 0 <= i < 8

function method GetReg(r:int) : ARMReg
    requires 0 <= r <= 12;
{
         if r ==  0 then R0
    else if r ==  1 then R1
    else if r ==  2 then R2
    else if r ==  3 then R3
    else if r ==  4 then R4
    else if r ==  5 then R5
    else if r ==  6 then R6
    else if r ==  7 then R7
    else if r ==  8 then R8
    else if r ==  9 then R9
    else if r == 10 then R10
    else if r == 11 then R11
    else R12 
}

// Make it as easy as possible for Z3 to see that the registers below are unique
function method ApplyPerm(i:int, perm:perm_index) : int
{
    if i + perm >= 8 then i + perm - 8 else i + perm
}

predicate method Even(i:int) { i % 2 == 0 }

function method CheapMod16(j:int) : int
{
    if j < 16 then j 
    else if j < 32 then j - 16 
    else if j < 48 then j - 32 
    else if j < 64 then j - 48 
    else j - 64
}

#endverbatim

procedure {:refined} Body_00_15(
    {:inline} i:SHA_step,
    {:inline} perm:perm_index,
    {:inline} input_slot:word,
    {:inline} i_plus_2:word,
    {:inline} i_plus_15:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout{:operand} t0:word,
    inout{:operand} t1:word,
    inout{:operand} t2:word,
    inout{:operand} t3:word,
    inout{:operand} t4:word,
    //inout{:operand} inp:word,
    inout{:operand} a:word,
         {:operand} b:word,
         {:operand} c:word,
    inout{:operand} d:word,
         {:operand} e:word,
         {:operand} f:word,
         {:operand} g:word,
    inout{:operand} h:word)
requires/ensures
    //WordAligned(sp);
    ValidAddr(mem, sp + input_slot);
reads 
    sp; globals;
modifies 
    mem; lr;
requires {:refined false}
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(GetReg(if Even(i) then 12 else 3));
    @t3 == OReg(GetReg(if Even(i) then  3 else 12));
    @t4 == OReg(R1);
    //@inp == OReg(R1);
    @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
    @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
    @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
    @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
    @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
    @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
    @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
    @h  == OReg(GetReg(4+ApplyPerm(7, perm)));
requires/ensures
    // Stack is accessible
    forall j {ValidAddr(mem, sp+j*4)} { mem?[sp+j*4] } :: 0 <= j < 18 ==> ValidAddr(mem, sp + j*4);

requires
    // K table adjusted properly
    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
    lr == AddressOfGlobal(K_SHA256s()) + 4*i;
    SeqLength(globals[K_SHA256s()]) == 64;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    // TODO: Remove this when we have if/else
    requires i >= 16;
    
    SeqLength(input) == 16;

    i < 15 ==> ValidAddr(mem, t4) && mem[t4] == input[i+1];
    input_slot == CheapMod16(i)*4;

    i >= 15 ==> i_plus_2  == CheapMod16(i+ 2)*4 && ValidAddr(mem, sp+i_plus_2);
    i >= 15 ==> i_plus_15 == CheapMod16(i+15)*4 && ValidAddr(mem, sp+i_plus_15);

    // t4 doesn't alias the stack
    i < 16 ==> t4 < sp || t4 >= sp + 18*4;

    // SHA semantics
    SeqLength(trace_in.H) > 0;
    IsSHA256TraceReadyForStep(trace_in, i);
    if i == 0 || i >= 16 then last(last(trace_in.atoh)) == atoh_c(a, b, c, d, e, f, g, h)
    else last(last(trace_in.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h);

    // t1 holds the current value of W
    t1 == (if (i < 16) then input[i] else last(trace_in.W)[i]);

    // The first 16 values in W are the byte-swapped version of the input words
    forall j :: 0 <= j < 16 ==> last(trace_in.W)[j] == bswap32(input[j]);

    // All previous Ws are in memory where we expect them
    i < 16 ==> (forall j :: 0 <= j < i ==> last(trace_in.W)[j] == mem[sp + j*4]);
    16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(trace_in.W)[j] == mem[sp + CheapMod16(j)*4]);

    // TODO: Remove when we have if/else and can skip the add of t2 when i == 0
    requires i == 0 ==> t2 == 0;

    // SHA tactics
    t3 == BitwiseXor(b, c);
    i >= 16 ==> RotateRight(t0, Sigma1(0)) == BSIG1(e);

ensures
    t2 == BitwiseXor(a, b);
    t3 == Maj(a, b, c);
    i < 16 ==> a == old(BitwiseAdd32(a, t2));
    lr == BitwiseAdd32(old(lr), 4);

    // Updated input ptr
    if i < 15 then t4 == BitwiseAdd32(old(t4), 4)   // Advanced input ptr
    else if i == 15 then mem[sp+17*4] == old(t4)    // We stored the advanced input ptr on the stack
    else mem[sp+17*4] == old(mem[sp+17*4]);         // We preserved the input ptr on the stack

// No longer need this in the ensures, since it's implied by the clauses below
//    let T1 := BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(old(h), BSIG1(e)),
//                                                     Ch(e,f,g)),
//                                        K_SHA256(i)),
//                           bswap32(old(t1))) in
//        d == BitwiseAdd32(old(d), T1)
//     && h == BitwiseAdd32(T1, BSIG0(a));

    exists trace_out:SHA256Trace ::
        IsSHA256TraceReadyForStep(trace_out, i+1)
     && trace_out.M == trace_in.M
     && trace_out.H == trace_in.H
     && trace_out.W == trace_in.W
     // t1 holds the next value of W
     && t1 == (if i + 1 < 16 then input[i + 1] else if i + 1 < 64 then mem[sp + i_plus_2] else t1) //last(trace_out.W)[i + 1] else t1)
     // Initial Ws are laid out in memory
     && (i + 1 < 16 ==> (forall j :: 0 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + j*4]))
     // Remaining Ws are laid out in memory
     && (16 <= i + 1 < 64 ==> (forall j :: i+1 - 16 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + CheapMod16(j)*4]))
     // The atohs almost match the outgoing variables
     && (let old_a := (if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2))) in
         last(last(trace_out.atoh)) == atoh_c(BitwiseAdd32(h, t3), old_a, old(b), old(c), d, old(e), old(f), old(g)));
{
//    //if i < 16
//    //  if i == 15
////          assert 68 == 17*4;    // OBSERVE
////          rSTR(t4, sp, 68 /*== 17*4*/);     // Save a copy of the incremented input pointer, so we can free up t4
//    //  end if
//
//    rEORShift(t0, e, e, RORShift(Sigma1(1) - Sigma1(0)));
//    // TODO: When i = 0, t2 = 0, so this is a no op.  We can skip it.  We can also remove the XOR that clears t2
//    rADDWrap(a, a, t2);  // h += Maj(a,b,c) from the past?
//    rEORShift(t0, t0, e, RORShift(Sigma1(2) - Sigma1(0)));   // Sigma1(e)
//    rREV(t1, t1);
//
//    //end if--------

    rLDRglobal(t2, K_SHA256s().sym, lr, 0);
    rADDWrap(lr, lr, 4);    // TODO: OpenSSL does this in one instruction with a load-and-increment.  
    rADDWrap(h, h, t1);      //  h+=X[i]  BP: X[i] = input[i]?
    //assert h == BitwiseAdd32(old(h), bswap32(old(t1)));
    rSTR(t1, sp, input_slot);  // @ BP: Save a copy of input[i] for use in subsequent W calculations
    rEOR(t1, f, g);
    ghost var old_h := h;
    //assert t0 == BitwiseXor(BitwiseXor(e, RotateRight(e, 5)), RotateRight(e, 19));
    rADDWrapShift(h, h, t0, RORShift(Sigma1(0))); // h += Sigma1(e)

    // Prove that we computed Sigma1(e) correctly:
    forall :: h == BitwiseAdd32(old_h, BSIG1(e))
    {
        reveal BSIG1;
        lemma_RotateRightCommutesXor(e, 6, 11, 25);
    }

    rAND(t1, t1, e);
    rADDWrap(h, h, OConst(K_SHA256(i)));      // h += K256(i)
    rEOR(t1, t1, g);     // Ch(e,f,g)
    
    assert t1 == Ch(e, f, g) by { lemma_Ch(e, f, g, t1); }

    rEORShift(t0, a, a, RORShift(Sigma0(1) - Sigma0(0)));
    rADDWrap(h, h, t1);  // h += Ch(e,f,g)

    ghost var old_t1 := if i < 16 then bswap32(old(t1)) else old(t1);
    assert h == BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(old(h), old_t1), BSIG1(e)), K_SHA256(i)), Ch(e, f, g));
    lemma_BitwiseAdd32Associates5(old(h), old_t1, BSIG1(e), K_SHA256(i), Ch(e, f, g), h);

//    #if $i==31
//        and  $t2,$t2,#0xff
//        cmp  $t2,#0xf2      @ done?
//    #endif

    // if $i<15
//         rLDR(t1, t4, 0);    // Prefetch
//         rADDWrap(t4, t4, 4);   // Advance to the next input  // TODO: OpenSSL does this in one instruction with a load-and-increment
//         rEOR(t2, a, b);            //  a^b, b^c in next round
    // else
       rLDR(t1, sp, i_plus_2);     // @ from future BODY_16_xx 
       rEOR(t2, a, b);             //  a^b, b^c in next round
       rLDR(t4, sp, i_plus_15);    // @ from future BODY_16_xx
    // endif
    rEORShift(t0,t0,a, RORShift(Sigma0(2)-Sigma0(0))); // Sigma0(a)
    rAND(t3,t3,t2);      // (b^c)&=(a^b)
    rADDWrap(d,d,h);     // d+=h
    rEOR(t3,t3,b);       // Maj(a,b,c)
    assert t3 == Maj(a,b,c) by { lemma_Maj(a, b, c, t3); }
    old_h := h;
    rADDWrapShift(h,h,t0, RORShift(Sigma0(0)));   // h+=Sigma0(a)

    // Prove we computed Sigma0(a) correctly:
    forall :: h == (old_h + BSIG0(a)) % 0x1_0000_0000
    {
        reveal BSIG0;
        lemma_RotateRightCommutesXor(a, 2, 13, 22);
    }

    // Prove that stack is still valid
    forall j :| 0 <= j < 18 
        :: ValidAddr(mem, sp + j * 4)
    {
        assert ValidAddr(old(mem), sp + j * 4);
    }

    ghost var T1 := BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(old(h), BSIG1(e)),
                                                           Ch(e,f,g)),
                                              K_SHA256(i)),
                                 old_t1);
    //assert h == BitwiseAdd32(T1, BSIG0(a));
    assert BitwiseAdd32(h, t3) == BitwiseAdd32(T1, BitwiseAdd32(BSIG0(a), t3)) by
           { lemma_BitwiseAdd32Associates3'(T1, BSIG0(a), t3); }

    // Construct a trace_out
    ghost var old_a := if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2));
    ghost var old_atoh := old(atoh_c(old_a, b, c, d, e, f, g, h));
    //assert last(last(trace_in.atoh)) == old_atoh;                                   
    ghost var new_atoh := atoh_c(BitwiseAdd32(h, t3), old_a, old(b), old(c), d, old(e), old(f), old(g));
    assert i == 0 ==> BitwiseAdd32(old(a), 0) == old(a);   // OBSERVE
    assert old_atoh.a == a;     // OBSERVE
     

    ghost var new_atoh_list := last(trace_in.atoh) + seq(new_atoh);
    ghost var trace_out:SHA256Trace := trace_in.(atoh := SeqDrop(trace_in.atoh, SeqLength(trace_in.H)-1) + seq(trace_in.atoh[SeqLength(trace_in.H)-1] + seq(new_atoh)));

    // OBSERVE: Triggers gallore!
    assert TBlk(SeqLength(trace_in.H)-1) && TBlk(SeqLength(trace_in.H)) && TStep(i) && TStep(i + 1);
    ghost var superfluous_state_in  := SHA256_state_c(last(trace_in.H), last(trace_in.W), old_atoh);
    ghost var superfluous_state_out := SHA256_state_c(last(trace_out.H), last(trace_out.W), new_atoh);
    lemma_SHA256TransitionOKAfterSettingAtoH(trace_in, superfluous_state_in, trace_out, superfluous_state_out, i);

    assert IsSHA256TraceReadyForStep(trace_out, i+1);
     assert trace_out.M == trace_in.M;
     assert trace_out.H == trace_in.H;
     assert trace_out.W == trace_in.W;
     // t1 holds the next value of W
     assert t1 == (if i + 1 < 16 then input[i + 1] else if i + 1 < 64 then mem[sp + i_plus_2] else t1);
             //last(trace_out.W)[i + 1] else t1);
     // Initial Ws are laid out in memory
     assert (i + 1 < 16 ==> (forall j :: 0 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + j*4]));
     // Remaining Ws are laid out in memory
     assert input_slot == CheapMod16(i)*4;
     assert (16 <= i + 1 < 64 ==> (forall j :: i+1 - 16 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + CheapMod16(j)*4]));
     // The atohs almost match the outgoing variables
     assert (let old_a := (if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2))) in
         last(last(trace_out.atoh)) == atoh_c(BitwiseAdd32(h, t3), old_a, old(b), old(c), d, old(e), old(f), old(g)));
}

#verbatim
} // end module sha256_refined_Body_00_15 

module sha256_refined_Body_16_XX {
import opened sha256_refined_Body_16_XX_ARMdecls = ARMdecls
import opened sha256_refined_Body_16_XX_sha256_refined_Body_00_15 = sha256_refined_Body_00_15
import opened sha256_refined_Body_16_XX_ARMspartan = ARMspartan
import opened sha256_refined_Body_16_XX_sha256_i = sha256_i
import opened sha256_refined_Body_16_XX_sha256_refined_helpers_i = sha256_refined_helpers_i
#endverbatim

procedure {:refined} Body_16_XX( 
    {:inline} i:SHA_step,
    {:inline} perm:perm_index,
    {:inline} input_slot:word,
    {:inline} input_slot_9:word,
    ghost trace_in:SHA256Trace,
    ghost input:seq(word),
    inout{:operand} t0:word,
    inout{:operand} t1:word,
    inout{:operand} t2:word,
    inout{:operand} t3:word,
    inout{:operand} t4:word,
    //inout{:operand} inp:word,
    inout{:operand} a:word,
         {:operand} b:word,
         {:operand} c:word,
    inout{:operand} d:word,
         {:operand} e:word,
         {:operand} f:word,
         {:operand} g:word,
    inout{:operand} h:word)

requires/ensures
    // Stack is accessible
    forall j {ValidAddr(mem, sp+j*4)} { mem?[sp+j*4] } :: 0 <= j < 18 ==> ValidAddr(mem, sp + j*4);
reads 
    sp; globals;
modifies 
    mem; lr;
requires {:refined false}
    @t0 == OReg(R0);
    @t1 == OReg(R2);
    @t2 == OReg(GetReg(if Even(i) then 12 else 3));
    @t3 == OReg(GetReg(if Even(i) then  3 else 12));
    @t4 == OReg(R1);
    //@inp == OReg(R1);
    @a  == OReg(GetReg(4+ApplyPerm(0, perm)));
    @b  == OReg(GetReg(4+ApplyPerm(1, perm)));
    @c  == OReg(GetReg(4+ApplyPerm(2, perm)));
    @d  == OReg(GetReg(4+ApplyPerm(3, perm)));
    @e  == OReg(GetReg(4+ApplyPerm(4, perm)));
    @f  == OReg(GetReg(4+ApplyPerm(5, perm)));
    @g  == OReg(GetReg(4+ApplyPerm(6, perm)));
    @h  == OReg(GetReg(4+ApplyPerm(7, perm)));

requires
    i >= 16;
    input_slot == CheapMod16(i)*4;
    input_slot_9 == CheapMod16(i+9)*4;
    ValidAddr(mem, sp + input_slot);
    ValidAddr(mem, sp + input_slot_9); 

    // K table adjusted properly
    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
    lr == AddressOfGlobal(K_SHA256s()) + 4*i;
    SeqLength(globals[K_SHA256s()]) == 64;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    SeqLength(input) == 16;

    ValidAddr(mem, sp + CheapMod16(i +  2)*4);
    ValidAddr(mem, sp + CheapMod16(i + 15)*4);

    t3 == BitwiseXor(b, c);

    // SHA semantics
    SeqLength(trace_in.H) > 0;
    IsSHA256TraceReadyForStep(trace_in, i);
    last(last(trace_in.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h);

    // The first 16 values in W are the byte-swapped version of the input words
    forall j :: 0 <= j < 16 ==> last(trace_in.W)[j] == bswap32(input[j]);

    // All previous Ws are in memory where we expect them
    16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(trace_in.W)[j] == mem[sp + CheapMod16(j)*4]);

    // t1 and t4 should already hold previous W values
    t1 == mem[sp + CheapMod16(i+1)*4];
    t4 == mem[sp + CheapMod16(i+14)*4];
ensures 
    t2 == BitwiseXor(a, b);
    t3 == Maj(a, b, c);
    //a == old(BitwiseAdd32(a, t2));
    lr == BitwiseAdd32(old(lr), 4);

    mem[sp+17*4] == old(mem[sp+17*4]);         // We preserved the input ptr on the stack

    exists trace_out:SHA256Trace ::
        IsSHA256TraceReadyForStep(trace_out, i+1)
     && trace_out.M == trace_in.M
     && trace_out.H == trace_in.H
     && trace_out.W == trace_in.W
     // t1 holds the next value of W
     && t1 == (if i + 1 < 64 then mem[sp + CheapMod16(i + 2)*4] else t1) 

     // Remaining Ws are laid out in memory
     && (i + 1 < 64 ==> (forall j :: i+1 - 16 <= j < i+1 ==> last(trace_out.W)[j] == mem[sp + CheapMod16(j)*4]))

     // The atohs almost match the outgoing variables
     //&& (let old_a := (if i == 0 || i >= 16 then old(a) else old(BitwiseAdd32(a, t2))) in
     && (let old_a := old(BitwiseAdd32(a, t2)) in
         last(last(trace_out.atoh)) == atoh_c(BitwiseAdd32(h, t3), old_a, old(b), old(c), d, old(e), old(f), old(g)));
{
    rMOVShift(t0, t1, RORShift(sigma0(0)));
    rADDWrap(a, a, t2);  // h+=Maj(a,b,c) from the past
    rMOVShift(t2, t4, RORShift(sigma1(0)));
    rEORShift(t0,t0,t1,RORShift(sigma0(1)));
    rEORShift(t2,t2,t4,RORShift(sigma1(1)));
    rEORShift(t0,t0,t1,LSRShift(sigma0(2)));     // sigma0(X[i+1])
    assert t0 == SSIG0(t1) by { reveal SSIG0; }

    rLDR(t1, sp, input_slot);
    rEORShift(t2,t2,t4, LSRShift(sigma1(2)));     // sigma1(X[i+14])
    assert t2 == SSIG1(t4) by { reveal SSIG1; }
    rLDR(t4, sp, input_slot_9);

    rADDWrap(t2,t2,t0);
    rEORShift(t0,e,e,RORShift(Sigma1(1)-Sigma1(0)));    // from BODY_00_15
    rADDWrap(t1,t1,t2);
    rEORShift(t0,t0,e,RORShift(Sigma1(2)-Sigma1(0)));  // Sigma1(e)  BP: Almost

    // Prove that we computed Sigma1(e) correctly:
    forall :: RotateRight(t0, Sigma1(0)) == BSIG1(e)
    {
        reveal BSIG1;
        lemma_RotateRightCommutesXor(e, 6, 11, 25);
    }

    rADDWrap(t1,t1,t4);      // X[i]

    // From the spec (and PartialSHA256TraceHasCorrectWs):  (TODO: Probably need to trigger z.W[blk] and TStep(i))
    ghost var W := last(trace_in.W);
    assert TStep(i);
    assert W[i] == BitwiseAdd32(BitwiseAdd32(BitwiseAdd32(SSIG1(W[i-2]), W[i-7]), SSIG0(W[i-15])), W[i-16]);
//    assert W[i- 2] == mem[sp + CheapMod16(i + 14)*4];
//    assert W[i- 7] == mem[sp + CheapMod16(i +  9)*4];
//    assert W[i-15] == mem[sp + CheapMod16(i +  1)*4];
//    assert W[i-16] == mem[sp + CheapMod16(i +  0)*4] == mem[sp + input_slot];

    assert t1 == W[i] by {
        lemma_BitwiseAdd32Associates4(SSIG1(W[i-2]), W[i-7], SSIG0(W[i-15]), W[i-16], t1);
    }

    Body_00_15(i, perm, input_slot, CheapMod16(i + 2)*4, CheapMod16(i + 15)*4, trace_in, input,
               t0, t1, t2, t3, t4, 
               a, b, c, d, e, f, g, h);
}

#verbatim
} // end module sha256-refined_Body_16_XX
#endverbatim

#verbatim
//////////////////////////////////////////////
// Code to specify unrolling Body_16_XX
//////////////////////////////////////////////

module Body_16_XXLoopUnrollableCode refines UnrollableCode {

//import opened sha256_i
//import opened x86def_s
//import opened x86spartan
//import opened x86decls
import opened sha256_refined_Body_16_XX
export provides sp_refined_Body_16_XXLoopUnrolled, sp_code_Body_16_XXLoopUnrolled, sha256_refined_Body_16_XX //, sha256_i, x86def_s, x86spartan 
       reveals sp_trigger_Body_16_XXLoopUnrolled, sp_spec_Body_16_XXLoopUnrolled, Body_16_XXLoopStateInvariantBreakdown

datatype Body_16_XXLoopConstantState = Body_16_XXLoopConstantState(orig_mem:memmap, orig_trace:SHA256Trace, input:seq<word>) //, orig_mem:memmap, sp:word, globals:map(operand,seq(word)), )
datatype Body_16_XXLoopCodeParameters = Body_16_XXLoopCodeParameters()
datatype Body_16_XXLoopAuxiliaryState = Body_16_XXLoopAuxiliaryState(current_trace:SHA256Trace)

type GenericConstantState = Body_16_XXLoopConstantState
type GenericCodeParameters = Body_16_XXLoopCodeParameters
type GenericAuxiliaryState = Body_16_XXLoopAuxiliaryState

function method GenericIterationCount() : int { 48 }

predicate GenericFramingInvariant(sp_s0:sp_state, sp_sM:sp_state)
{
//    sp_state_eq(sp_sM, sp_s0)
// TODO: How do we specify generic updates to changing operands?  Or do say that all of them may change?
    reveal_ValidRegState();
    ValidState(sp_sM)
 && sp_state_eq(sp_sM, sp_update_olr(sp_sM, sp_update_mem(sp_sM, sp_update_ok(sp_sM, 
                sp_update_reg(R0, sp_sM, 
                sp_update_reg(R1, sp_sM, 
                sp_update_reg(R2, sp_sM, 
                sp_update_reg(R3, sp_sM, 
                sp_update_reg(R4, sp_sM, 
                sp_update_reg(R5, sp_sM, 
                sp_update_reg(R6, sp_sM, 
                sp_update_reg(R7, sp_sM, 
                sp_update_reg(R8, sp_sM, 
                sp_update_reg(R9, sp_sM, 
                sp_update_reg(R10, sp_sM, 
                sp_update_reg(R11, sp_sM, 
                sp_update_reg(R12, sp_sM, sp_s0)))))))))))))))))

//    sp_state_eq(sp_sM, sp_update_olr(sp_sM, sp_update_mem(sp_sM, sp_update_ok(sp_sM, sp_update(h, sp_sM, sp_update(d, sp_sM, sp_update(a, sp_sM, sp_update(t4, sp_sM, sp_update(t3, sp_sM, sp_update(t2, sp_sM, sp_update(t1, sp_sM, sp_update(t0, sp_sM, sp_s0))))))))))))
}

predicate Body_16_XXLoopStateInvariantBreakdown(
    orig_mem:memmap,
    mem:memmap,
    orig_trace:SHA256Trace,
    current_trace:SHA256Trace,
    i:int,
    sp:word,
    globals:map<operand,seq<word>>,
    lr:word,
    t1:word,
    t2:word,
    t3:word,
    t4:word,
    input:seq<word>,
    a:word, b:word, c:word, d:word, e:word, f:word, g:word, h:word
    )
{
    16 <= i <= 64
 && (forall j {:trigger ValidAddr(orig_mem, sp+j*4)} {:trigger sp+j*4 in orig_mem } :: 
         0 <= j < 18 ==> ValidAddr(orig_mem, sp + j*4))
 && (forall j {:trigger ValidAddr(mem, sp+j*4)} {:trigger sp+j*4 in mem } :: 
         0 <= j < 18 ==> ValidAddr(mem, sp + j*4))
 && ValidAddr(mem, sp + CheapMod16(i)*4)
 && ValidAddr(mem, sp + CheapMod16(i+9)*4)

    // K table adjusted properly
 && ValidGlobalsAddr(globals, K_SHA256s().sym, lr)
 && lr == AddressOfGlobal(K_SHA256s()) + 4*i
 && |globals[K_SHA256s()]| == 64
 && (forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j))

 && SeqLength(input) == 16

 && ValidAddr(mem, sp + CheapMod16(i +  2)*4)
 && ValidAddr(mem, sp + CheapMod16(i + 15)*4)

 && t3 == BitwiseXor(b, c)

    // SHA semantics
 && SeqLength(current_trace.H) > 0
 && IsSHA256TraceReadyForStep(current_trace, i)
 && current_trace.M == orig_trace.M
 && current_trace.H == orig_trace.H
 && current_trace.W == orig_trace.W
 && last(last(current_trace.atoh)) == atoh_c(BitwiseAdd32(a, t2), b, c, d, e, f, g, h)

    // The first 16 values in W are the byte-swapped version of the input words
 && (forall j :: 0 <= j < 16 ==> last(current_trace.W)[j] == bswap32(input[j]))

    // All previous Ws are in memory where we expect them
 && 16 <= i < 64 ==> (forall j :: i - 16 <= j < i ==> last(current_trace.W)[j] == mem[sp + CheapMod16(j)*4])

    // t1 and t4 should already hold previous W values
 && t1 == mem[sp + CheapMod16(i+1)*4]
 && t4 == mem[sp + CheapMod16(i+14)*4]

 // Additional postconditions
 && mem[sp+17*4] == orig_mem[sp+17*4]         // We preserved the input ptr on the stack
}

predicate GenericStateInvariant(c:GenericConstantState, s:sp_state, aux:GenericAuxiliaryState, i:int, p:GenericCodeParameters)
{
       reveal_ValidRegState();
       ValidState(s)
    && var perm := i % 8;
       Body_16_XXLoopStateInvariantBreakdown(
            c.orig_mem, sp_get_mem(s), 
            c.orig_trace, aux.current_trace, 
            i, sp_get_osp(s), sp_get_globals(s), sp_get_olr(s), 
           /*t1*/sp_get_reg(R2, s), 
           /*t2*/sp_get_reg(if Even(i) then R12 else R3, s), 
           /*t3*/sp_get_reg(if Even(i) then R3  else R12, s), 
           /*t4*/sp_get_reg(R1, s), 
           c.input,
           sp_get_reg(GetReg(4+ApplyPerm(0, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(1, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(2, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(3, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(4, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(5, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(6, perm)), s),
           sp_get_reg(GetReg(4+ApplyPerm(7, perm)), s) 
           )
}

 

function method GenericCodeIteration(i:int, p:GenericCodeParameters) : code
{
    var perm := i % 8;
    sp_code_Body_16_XX(i, perm, CheapMod16(i)*4, CheapMod16(i+9)*4, 
                       OReg(R0),
                       OReg(R2),
                       OReg(GetReg(if Even(i) then 12 else 3)),
                       OReg(GetReg(if Even(i) then  3 else 12)),
                       OReg(R1),
                       OReg(GetReg(4+ApplyPerm(0, perm))),
                       OReg(GetReg(4+ApplyPerm(1, perm))),
                       OReg(GetReg(4+ApplyPerm(2, perm))),
                       OReg(GetReg(4+ApplyPerm(3, perm))),
                       OReg(GetReg(4+ApplyPerm(4, perm))),
                       OReg(GetReg(4+ApplyPerm(5, perm))),
                       OReg(GetReg(4+ApplyPerm(6, perm))),
                       OReg(GetReg(4+ApplyPerm(7, perm)))) 
}

lemma lemma_GenericFramingInvariantTransitivity(sp_s1:sp_state, sp_s2:sp_state, sp_s3:sp_state)
{
}

lemma sp_lemma_GenericIterationPreservesInvariants(
    sp_b0:sp_codes,
    sp_s0:sp_state,
    sp_sN:sp_state,
    i:int,
    p:GenericCodeParameters
    ) returns (
    sp_bM:sp_codes,
    sp_sM:sp_state
    )
{
    assume false;                           /****************************************** TODO *************/
//    reveal_x86_ValidState();
//    reveal_evalCodeOpaque();
//
//    var K1 := K_SHA256(2*i);
//    var K2 := K_SHA256(2*i+1);
//    var W_offset1 := 4*(2*i);
//    var W_offset2 := 4*(2*i+1);
//    var W_taint := p.W_taint;
//    sp_bM, sp_sM := sp_refined_ComputeTwoSteps_SHA256_core(sp_b0, sp_s0, sp_sN, K1, K2, W_offset1, W_offset2, W_taint);
//
//    forall sp_id:sp_int, c:GenericConstantState, aux0:GenericAuxiliaryState {:trigger sp_trigger_GenericUnrolledChunk(sp_id, c, aux0)}
//        | sp_trigger_GenericUnrolledChunk(sp_id, c, aux0)
//        ensures sp_spec_GenericUnrolledChunk(c, aux0, sp_s0, sp_sM, i, i+1, p);
//    {
//        reveal_sp_spec_ComputeTwoSteps_SHA256_core();
//        assert sp_trigger_ComputeTwoSteps_SHA256_core(1, i, c.W_id, aux0.current_atoh, aux0.current_z, 2*i, aux0.current_state);
//        reveal_sp_spec_GenericUnrolledChunk();
//        assert sp_trigger_GenericUnrolledChunk(sp_id, c, aux0);
//        if sp_s0.ok && GenericStateInvariant(c, sp_s0, aux0, i, p) {
//            assert sp_sM.ok;
//            ghost var stack := sp_get_stack(sp_sM);
//            ghost var final_atoh, final_z :| final_atoh == atoh_c(sp_get_reg(X86Ebp, sp_sM), stack[0][0], stack[0][1], stack[0][2], stack[0][3], stack[0][4], stack[0][5], stack[0][6]) && IsSHA256ReadyForStep(final_z, aux0.current_state.(atoh := final_atoh), 2*i + 2) && |final_z.H| == |aux0.current_z.H| && final_z.M == aux0.current_z.M;
//            ghost var final_state := aux0.current_state.(atoh := final_atoh);
//            var auxM := aux0.(current_atoh := final_atoh, current_z := final_z, current_state := final_state);
//            assert GenericStateInvariant(c, sp_sM, auxM, i+1, p);
//        }
//    }
}

function method sp_code_Body_16_XXLoopUnrolled() : code
{
    Block(sp_code_GenericUnrolledChunk(0, GenericIterationCount(), Body_16_XXLoopCodeParameters()))
}

// The signature for the following lemma was generated by giving procedure Body_16_XXLoopUnrolled a body and running Spartan on it.

//lemma sp_refined_Body_16_XXLoopUnrolled(sp_b0:sp_codes, sp_s0:sp_state, sp_sN:sp_state)
//  returns (sp_bM:sp_codes, sp_sM:sp_state)
//  requires sp_require(sp_b0, sp_code_Body_16_XXLoopUnrolled(W_taint), sp_s0, sp_sN)
//  ensures  sp_ensure(sp_b0, sp_bM, sp_s0, sp_sM, sp_sN)
//  ensures  forall sp_id:sp_int, W_id:heaplet_id, orig_state:SHA256_state, orig_z:SHA256Trace{:trigger sp_trigger_Body_16_XXLoopUnrolled(sp_id, W_id, orig_state, orig_z)} :: sp_trigger_Body_16_XXLoopUnrolled(sp_id, W_id, orig_state, orig_z) ==> sp_spec_Body_16_XXLoopUnrolled(W_id, W_taint, orig_state, orig_z, sp_get_ok(sp_s0), sp_get_ok(sp_sM), sp_get_reg(X86Esi, sp_s0), sp_get_mem(sp_s0), sp_get_flags(sp_s0), sp_get_flags(sp_sM), sp_get_stack(sp_s0), sp_get_stack(sp_sM), sp_get_reg(X86Eax, sp_s0), sp_get_reg(X86Eax, sp_sM), sp_get_reg(X86Ebx, sp_s0), sp_get_reg(X86Ebx, sp_sM), sp_get_reg(X86Ecx, sp_s0), sp_get_reg(X86Ecx, sp_sM), sp_get_reg(X86Edx, sp_s0), sp_get_reg(X86Edx, sp_sM), sp_get_reg(X86Edi, sp_s0), sp_get_reg(X86Edi, sp_sM), sp_get_reg(X86Ebp, sp_s0), sp_get_reg(X86Ebp, sp_sM))
//  ensures  sp_state_eq(sp_sM, sp_update_reg(X86Ebp, sp_sM, sp_update_reg(X86Edi, sp_sM, sp_update_reg(X86Edx, sp_sM, sp_update_reg(X86Ecx, sp_sM, sp_update_reg(X86Ebx, sp_sM, sp_update_reg(X86Eax, sp_sM, sp_update_stack(sp_sM, sp_update_flags(sp_sM, sp_update_ok(sp_sM, sp_s0))))))))))
//{
//    var n := GenericIterationCount();
//    var p := Body_16_XXLoopCodeParameters(W_taint);
//    var orig_stack := sp_get_stack(sp_s0);
//    sp_bM, sp_sM := sp_lemma_GenericUnrolled(sp_b0, sp_s0, sp_sN, p);
//
//    reveal_x86_ValidState();
//
//    forall sp_id:sp_int, W_id:heaplet_id, orig_state:SHA256_state, orig_z:SHA256Trace {:trigger sp_trigger_Body_16_XXLoopUnrolled(sp_id, W_id, orig_state, orig_z)}
//        | sp_trigger_Body_16_XXLoopUnrolled(sp_id, W_id, orig_state, orig_z)
//        ensures sp_spec_Body_16_XXLoopUnrolled(W_id, W_taint, orig_state, orig_z, sp_get_ok(sp_s0), sp_get_ok(sp_sM), sp_get_reg(X86Esi, sp_s0), sp_get_mem(sp_s0), sp_get_flags(sp_s0), sp_get_flags(sp_sM), sp_get_stack(sp_s0), sp_get_stack(sp_sM), sp_get_reg(X86Eax, sp_s0), sp_get_reg(X86Eax, sp_sM), sp_get_reg(X86Ebx, sp_s0), sp_get_reg(X86Ebx, sp_sM), sp_get_reg(X86Ecx, sp_s0), sp_get_reg(X86Ecx, sp_sM), sp_get_reg(X86Edx, sp_s0), sp_get_reg(X86Edx, sp_sM), sp_get_reg(X86Edi, sp_s0), sp_get_reg(X86Edi, sp_sM), sp_get_reg(X86Ebp, sp_s0), sp_get_reg(X86Ebp, sp_sM));
//    {
//        var c := Body_16_XXLoopConstantState(W_id, orig_state, orig_z, orig_stack);
//        var aux0 := Body_16_XXLoopAuxiliaryState(orig_state.atoh, orig_z, orig_state);
//
//        assert sp_trigger_GenericUnrolledChunk(sp_id, c, aux0);
//        assert sp_spec_GenericUnrolledChunk(c, aux0, sp_s0, sp_sM, 0, n, p);
//        reveal_sp_spec_GenericUnrolledChunk();
//        reveal_sp_spec_Body_16_XXLoopUnrolled();
//
//        if sp_s0.ok && GenericStateInvariant(c, sp_s0, aux0, 0, p)
//        {
//            var auxM :| GenericStateInvariant(c, sp_sM, auxM, GenericIterationCount(), p);
//            assert Body_16_XXLoopStateInvariantBreakdown(W_id, orig_state, orig_z, sp_get_stack(sp_s0), sp_get_stack(sp_sM), sp_get_mem(sp_sM), sp_get_reg(X86Ebp, sp_sM), sp_get_reg(X86Esi, sp_sM), auxM.current_atoh, auxM.current_z, auxM.current_state, GenericIterationCount(), W_taint);
//        }
//    }
//}

lemma sp_refined_Body_16_XXLoopUnrolled(sp_b0:sp_codes, sp_s0:sp_state, sp_sN:sp_state)
  returns (sp_bM:sp_codes, sp_sM:sp_state)
  requires sp_require(sp_b0, sp_code_Body_16_XXLoopUnrolled(), sp_s0, sp_sN)
  ensures  sp_ensure(sp_b0, sp_bM, sp_s0, sp_sM, sp_sN)
  ensures  forall sp_id:sp_int, trace_in:SHA256Trace, input:seq<word>{:trigger sp_trigger_Body_16_XXLoopUnrolled(sp_id, trace_in, input)} :: sp_trigger_Body_16_XXLoopUnrolled(sp_id, trace_in, input) ==> sp_spec_Body_16_XXLoopUnrolled(trace_in, input, sp_get_ok(sp_s0), sp_get_ok(sp_sM), sp_get_osp(sp_s0), sp_get_globals(sp_s0), sp_get_mem(sp_s0), sp_get_mem(sp_sM), sp_get_olr(sp_s0), sp_get_olr(sp_sM), sp_get_reg(R0, sp_s0), sp_get_reg(R0, sp_sM), sp_get_reg(R1, sp_s0), sp_get_reg(R1, sp_sM), sp_get_reg(R2, sp_s0), sp_get_reg(R2, sp_sM), sp_get_reg(R3, sp_s0), sp_get_reg(R3, sp_sM), sp_get_reg(R4, sp_s0), sp_get_reg(R4, sp_sM), sp_get_reg(R5, sp_s0), sp_get_reg(R5, sp_sM), sp_get_reg(R6, sp_s0), sp_get_reg(R6, sp_sM), sp_get_reg(R7, sp_s0), sp_get_reg(R7, sp_sM), sp_get_reg(R8, sp_s0), sp_get_reg(R8, sp_sM), sp_get_reg(R9, sp_s0), sp_get_reg(R9, sp_sM), sp_get_reg(R10, sp_s0), sp_get_reg(R10, sp_sM), sp_get_reg(R11, sp_s0), sp_get_reg(R11, sp_sM), sp_get_reg(R12, sp_s0), sp_get_reg(R12, sp_sM))
  ensures  sp_state_eq(sp_sM, sp_update_reg(R12, sp_sM, sp_update_reg(R11, sp_sM, sp_update_reg(R10, sp_sM, sp_update_reg(R9, sp_sM, sp_update_reg(R8, sp_sM, sp_update_reg(R7, sp_sM, sp_update_reg(R6, sp_sM, sp_update_reg(R5, sp_sM, sp_update_reg(R4, sp_sM, sp_update_reg(R3, sp_sM, sp_update_reg(R2, sp_sM, sp_update_reg(R1, sp_sM, sp_update_reg(R0, sp_sM, sp_update_olr(sp_sM, sp_update_mem(sp_sM, sp_update_ok(sp_sM, sp_s0)))))))))))))))))
{
//  reveal_sp_code_Body_16_XXLoopUnrolled();
//  var sp_old_s:sp_state := sp_s0;
//  ghost var sp_ltmp1, sp_cM:sp_code, sp_ltmp2 := sp_lemma_block(sp_b0, sp_s0, sp_sN);
//  sp_sM := sp_ltmp1;
//  sp_bM := sp_ltmp2;
//  var sp_b1:sp_codes := sp_get_block(sp_cM);
//  sp_sM := sp_lemma_empty(sp_s0, sp_sM);
//  sp_abstract_Body_16_XXLoopUnrolled(sp_get_ok(sp_s0), sp_get_osp(sp_s0), sp_get_globals(sp_s0), sp_get_mem(sp_s0), sp_get_olr(sp_s0), sp_get_reg(R0, sp_s0), sp_get_reg(R1, sp_s0), sp_get_reg(R2, sp_s0), sp_get_reg(R3, sp_s0), sp_get_reg(R4, sp_s0), sp_get_reg(R5, sp_s0), sp_get_reg(R6, sp_s0), sp_get_reg(R7, sp_s0), sp_get_reg(R8, sp_s0), sp_get_reg(R9, sp_s0), sp_get_reg(R10, sp_s0), sp_get_reg(R11, sp_s0), sp_get_reg(R12, sp_s0));


    var n := GenericIterationCount();
    var p := Body_16_XXLoopCodeParameters();
    sp_bM, sp_sM := sp_lemma_GenericUnrolled(sp_b0, sp_s0, sp_sN, p);

    //reveal_x86_ValidState();
    forall sp_id:sp_int, trace_in:SHA256Trace, input:seq<word>{:trigger sp_trigger_Body_16_XXLoopUnrolled(sp_id, trace_in, input)} 
        | sp_trigger_Body_16_XXLoopUnrolled(sp_id, trace_in, input) 
        ensures sp_spec_Body_16_XXLoopUnrolled(trace_in, input, sp_get_ok(sp_s0), sp_get_ok(sp_sM), sp_get_osp(sp_s0), sp_get_globals(sp_s0), sp_get_mem(sp_s0), sp_get_mem(sp_sM), sp_get_olr(sp_s0), sp_get_olr(sp_sM), sp_get_reg(R0, sp_s0), sp_get_reg(R0, sp_sM), sp_get_reg(R1, sp_s0), sp_get_reg(R1, sp_sM), sp_get_reg(R2, sp_s0), sp_get_reg(R2, sp_sM), sp_get_reg(R3, sp_s0), sp_get_reg(R3, sp_sM), sp_get_reg(R4, sp_s0), sp_get_reg(R4, sp_sM), sp_get_reg(R5, sp_s0), sp_get_reg(R5, sp_sM), sp_get_reg(R6, sp_s0), sp_get_reg(R6, sp_sM), sp_get_reg(R7, sp_s0), sp_get_reg(R7, sp_sM), sp_get_reg(R8, sp_s0), sp_get_reg(R8, sp_sM), sp_get_reg(R9, sp_s0), sp_get_reg(R9, sp_sM), sp_get_reg(R10, sp_s0), sp_get_reg(R10, sp_sM), sp_get_reg(R11, sp_s0), sp_get_reg(R11, sp_sM), sp_get_reg(R12, sp_s0), sp_get_reg(R12, sp_sM))
    {
        var c := Body_16_XXLoopConstantState(sp_get_mem(sp_s0), trace_in, input);
        var aux0 := Body_16_XXLoopAuxiliaryState(trace_in);

        assert sp_trigger_GenericUnrolledChunk(sp_id, c, aux0);
        assert sp_spec_GenericUnrolledChunk(c, aux0, sp_s0, sp_sM, 0, n, p);
        reveal_sp_spec_GenericUnrolledChunk();
        reveal_sp_spec_Body_16_XXLoopUnrolled();

        if sp_s0.ok && GenericStateInvariant(c, sp_s0, aux0, 0, p)
        {
            var auxM :| GenericStateInvariant(c, sp_sM, auxM, GenericIterationCount(), p);
            assert Body_16_XXLoopStateInvariantBreakdown(
                       sp_get_mem(sp_s0),
                       sp_get_mem(sp_sM),
                       trace_in,
                       auxM.current_trace,
                       64,
                       sp_get_osp(sp_sM),
                       sp_get_globals(sp_sM),
                       sp_get_olr(sp_sM),
                       sp_get_reg(R2, sp_sM),   // t1
                       sp_get_reg(R12, sp_sM),  // t2
                       sp_get_reg(R3, sp_sM),   // t3
                       sp_get_reg(R1, sp_sM),   // t4
                       input,
                       sp_get_reg(R4, sp_sM),   // a
                       sp_get_reg(R5, sp_sM),   // b
                       sp_get_reg(R6, sp_sM),   // c
                       sp_get_reg(R7, sp_sM),   // d
                       sp_get_reg(R8, sp_sM),   // e
                       sp_get_reg(R9, sp_sM),   // f
                       sp_get_reg(R10, sp_sM),  // g
                       sp_get_reg(R11, sp_sM)); // h
        }
    }
}


#endverbatim

//// Spartan-level declaration of the compact loop, so that other Spartan procedures can call it
procedure {:refined} Body_16_XXLoopUnrolled(
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
    requires Body_16_XXLoopStateInvariantBreakdown(old(mem), mem, trace_in, trace_in, 16, sp, globals, lr, 
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
    reads  sp; globals;
    modifies mem; lr; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12;
    ensures  exists trace_out :: 
             Body_16_XXLoopStateInvariantBreakdown(old(mem), mem, trace_in, trace_out, 64, sp, globals, lr,
                                                   r2, r12, r3, r1, input,
                                                   r4, r5, r6, r7, r8, r9, r10, r11);
#verbatim
} // end module Body_16_XXLoopUnrollableCode

module sha256_block_data_order {
import opened sha256_refined_Body_16_XX_ARMdecls = ARMdecls
import opened sha256_refined_Body_16_XX_sha256_refined_Body_00_15 = sha256_refined_Body_00_15
import opened sha256_refined_Body_16_XX_ARMspartan = ARMspartan
import opened sha256_refined_Body_16_XX_sha256_i = sha256_i
import opened sha256_refined_Body_16_XX_sha256_refined_helpers_i = sha256_refined_helpers_i

#endverbatim



procedure {:refined} sha256_block_data_order(
    ghost trace_in:SHA256Trace,
    ghost input:seq(word)
    )
requires/ensures
    // Stack is accessible
    forall j {ValidAddr(mem, sp+j*4)} { mem?[sp+j*4] } :: 0 <= j < 18 ==> ValidAddr(mem, sp + j*4);
    
requires
    IsSHA256TraceReadyForStep(trace_in, 0);
    
//    // K table adjusted properly
//    ValidGlobalsAddr(globals, K_SHA256s().sym, lr);
//    lr == AddressOfGlobal(K_SHA256s()) + 4*i;
    ValidGlobals(globals);
    ValidGlobal(K_SHA256s());
    SeqLength(globals[K_SHA256s()]) == 64;
    forall j :: 0 <= j < 64 ==> globals[K_SHA256s()][j] == K_SHA256(j);

    let ctx := r0 in
    let input_ptr := r1 in
    let num_blocks := r2 in // Number of 64-byte blocks to process

     // Old H values are laid out in memory pointed at by ctx
        (forall j {ValidAddr(mem, ctx+j*4)} { mem?[ctx+j*4] } :: 0 <= j < 8 ==> ValidAddr(mem, ctx + j*4))
     && last(trace_in.H)[0] == mem[ctx + 0*4] == last(last(trace_in.atoh)).a
     && last(trace_in.H)[1] == mem[ctx + 1*4] == last(last(trace_in.atoh)).b
     && last(trace_in.H)[2] == mem[ctx + 2*4] == last(last(trace_in.atoh)).c
     && last(trace_in.H)[3] == mem[ctx + 3*4] == last(last(trace_in.atoh)).d
     && last(trace_in.H)[4] == mem[ctx + 4*4] == last(last(trace_in.atoh)).e
     && last(trace_in.H)[5] == mem[ctx + 5*4] == last(last(trace_in.atoh)).f
     && last(trace_in.H)[6] == mem[ctx + 6*4] == last(last(trace_in.atoh)).g
     && last(trace_in.H)[7] == mem[ctx + 7*4] == last(last(trace_in.atoh)).h
    //ConvertAtoHToSeq(last(trace_in.atoh)[0]) == last(trace_in.H);

     // TODO: Remove this once we have a while loop over num_blocks
     && num_blocks > 0

     // Ghost input matches in-memory input
     && SeqLength(input) == num_blocks*16
     && input_ptr + num_blocks*16 < 0x1_0000_0000
     && (forall j {ValidAddr(mem, input_ptr+j*4)} { mem?[input_ptr+j*4] } :: 
            0 <= j < num_blocks*16 ==> ValidAddr(mem, input_ptr + j*4)
                                   && mem[input_ptr + j*4] == input[j]
         )
     && (forall j :: 0 <= j < 16 ==> last(trace_in.W)[j] == bswap32(input[j]))

     // Anti-aliasing
     && (ctx + 7*4 < input_ptr || ctx > input_ptr + num_blocks*16)     // input_ptr != ctx
     && (ctx + 7*4 < sp || ctx >= sp + 18*4)                           // ctx != sp
     && (input_ptr + num_blocks*16 < sp || input_ptr >= sp + 18*4);              // input_ptr != sp

reads
    sp; globals;
modifies
    mem; r0; r1; r2; r3; r4; r5; r6; r7; r8; r9; r10; r11; r12; lr;
ensures
//    exists trace_out:SHA256Trace ::
//        IsSHA256TraceReadyForStep(trace_out, 64)
//     && trace_out.M == trace_in.M
//     && trace_out.H == trace_in.H
//     && trace_out.W == trace_in.W;
{
    // TODO: Need to save the value in R2 to the stack

    rLDR( r4, r0, 0);       // a
    rLDR( r5, r0, 4);       // b
    rLDR( r6, r0, 8);       // c
    rLDR( r7, r0, 12);      // d
    rLDR( r8, r0, 16);      // e
    rLDR( r9, r0, 20);      // f
    rLDR(r10, r0, 24);      // g
    rLDR(r11, r0, 28);      // h

    rLDRglobaladdr(lr, K_SHA256s().sym);

    // Set up the initial conditions for BODY_00_15
    rLDR(r2, r1, 0);        // t1 <- input[0]
    assert r2 == input[0];
    rADDWrap(r1, r1, 4);        // TODO: OpenSSL does this with a single LDR instruction
    rEOR(r3, r5, r6);       // t3 <- B xor C  "@magic"
    rEOR(r12, r12, r12);    // TODO: Remove this unnecessary clear once we have if/else in Body_00_15
    assert r12 == 0 by { lemma_XorSelfIsZero(); }
    
    Body_00_15(0, 0, 0, 2, 15, trace_in, SeqDrop(input, 16), 
               r0, r2, r12, r3, r1, 
               r4, r5, r6, r7, r8, r9, r10, r11);




}


#verbatim
}
#endverbatim
